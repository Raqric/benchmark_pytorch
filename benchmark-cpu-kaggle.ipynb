{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "vertical-armstrong",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-04-13T15:42:06.903615Z",
     "iopub.status.busy": "2021-04-13T15:42:06.902576Z",
     "iopub.status.idle": "2021-04-13T15:42:08.222350Z",
     "shell.execute_reply": "2021-04-13T15:42:08.221593Z"
    },
    "papermill": {
     "duration": 1.32983,
     "end_time": "2021-04-13T15:42:08.222524",
     "exception": false,
     "start_time": "2021-04-13T15:42:06.892694",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "#Author: Raquel Ricoy\n",
    "\n",
    "#Benchmark to study Kaggle's GPUs, CPUs and TPUs potential.\n",
    "#It's going to use Pytorch and to stablish a script to calculate its performance and GFLOPS.\n",
    "\n",
    "#Install pytorch\n",
    "#!conda install -y pytorch torchvision -c pytorch\n",
    "\n",
    "import torch\n",
    "import platform\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "import os\n",
    "#print(os.listdir(\"../input\"))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n",
    "\n",
    "#Importing Libraries needed for use torch\n",
    "import timeit\n",
    "import torch.utils.benchmark as benchmark\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "systematic-bishop",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-13T15:42:08.242720Z",
     "iopub.status.busy": "2021-04-13T15:42:08.241870Z",
     "iopub.status.idle": "2021-04-13T15:42:08.254756Z",
     "shell.execute_reply": "2021-04-13T15:42:08.253558Z"
    },
    "papermill": {
     "duration": 0.027073,
     "end_time": "2021-04-13T15:42:08.254971",
     "exception": false,
     "start_time": "2021-04-13T15:42:08.227898",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Platform processor: x86_64\n",
      "Platform architecture: ('64bit', '')\n",
      "Number of cores: 4\n"
     ]
    }
   ],
   "source": [
    "#Information about system\n",
    "print('Platform processor:', platform.processor())\n",
    "print('Platform architecture:', platform.architecture())\n",
    "\n",
    "#Number of threads\n",
    "num_cores = os.cpu_count()\n",
    "print('Number of cores:',num_cores)\n",
    "torch.set_num_threads(num_cores)\n",
    "num_threads = num_cores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "coated-space",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-13T15:42:08.274914Z",
     "iopub.status.busy": "2021-04-13T15:42:08.274259Z",
     "iopub.status.idle": "2021-04-13T15:42:08.278087Z",
     "shell.execute_reply": "2021-04-13T15:42:08.277572Z"
    },
    "papermill": {
     "duration": 0.017371,
     "end_time": "2021-04-13T15:42:08.278245",
     "exception": false,
     "start_time": "2021-04-13T15:42:08.260874",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Functions obtained from Torch Webpages por PyTorch Benchmarks\n",
    "def batched_dot_mul_sum(a, b):\n",
    "    '''Computes batched dot by multiplying and summing'''\n",
    "    return a.mul(b).sum(-1)\n",
    "\n",
    "\n",
    "def batched_dot_bmm(a, b):\n",
    "    '''Computes batched dot by reducing to bmm'''\n",
    "    a = a.reshape(-1, 1, a.shape[-1])\n",
    "    b = b.reshape(-1, b.shape[-1], 1)\n",
    "    return torch.bmm(a, b).flatten(-3)\n",
    "\n",
    "#Function developed by my own. Sum two vectors and save the output in vector C\n",
    "def sumVector(aVector,bVector):\n",
    "    lengthVectors = len(aVector);\n",
    "    cVector = torch.empty(lengthVectors,dtype=torch.float)\n",
    "    for i in torch.arange(0,lengthVectors):\n",
    "        cVector[i] = aVector[i] + bVector[i]\n",
    "    return cVector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "funny-moral",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-13T15:42:08.297095Z",
     "iopub.status.busy": "2021-04-13T15:42:08.296266Z",
     "iopub.status.idle": "2021-04-13T15:42:08.299168Z",
     "shell.execute_reply": "2021-04-13T15:42:08.298588Z"
    },
    "papermill": {
     "duration": 0.0158,
     "end_time": "2021-04-13T15:42:08.299315",
     "exception": false,
     "start_time": "2021-04-13T15:42:08.283515",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Method that do the benchmark and compare results with dot mul sum implementations and vectorSum\n",
    "def benchMark(sizes,nThreads):\n",
    "    results = []\n",
    "    if(len(sizes) == 0):\n",
    "        print(\"Parameter 'sizes' has to a have minumun of 1 parameters\")\n",
    "        return\n",
    "    if(len(nThreads)==0):\n",
    "        print(\"Parameter 'nThreads' has to a have minumun of 1 parameters\")\n",
    "    \n",
    "    for n in sizes:\n",
    "        # label and sub_label are the rows\n",
    "        # description is the column\n",
    "        label = 'Batched dot'\n",
    "        sub_label = f'[{n}, {n}]'\n",
    "        x = torch.ones((n, n))\n",
    "        for num_threads in nThreads:\n",
    "            results.append(benchmark.Timer(\n",
    "                stmt='batched_dot_mul_sum(x, x)',\n",
    "                setup='from __main__ import batched_dot_mul_sum',\n",
    "                globals={'x': x},\n",
    "                num_threads=num_threads,\n",
    "                label=label,\n",
    "                sub_label=sub_label,\n",
    "                description='mul/sum',\n",
    "            ).blocked_autorange(min_run_time=1))\n",
    "            results.append(benchmark.Timer(\n",
    "                stmt='batched_dot_bmm(x, x)',\n",
    "                setup='from __main__ import batched_dot_bmm',\n",
    "                globals={'x': x},\n",
    "                num_threads=num_threads,\n",
    "                label=label,\n",
    "                sub_label=sub_label,\n",
    "                description='bmm',\n",
    "            ).blocked_autorange(min_run_time=1))\n",
    "    compare = benchmark.Compare(results)\n",
    "    compare.print()\n",
    "    return compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "adopted-graphic",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-13T15:42:08.317859Z",
     "iopub.status.busy": "2021-04-13T15:42:08.317054Z",
     "iopub.status.idle": "2021-04-13T15:45:36.720378Z",
     "shell.execute_reply": "2021-04-13T15:45:36.721210Z"
    },
    "papermill": {
     "duration": 208.416779,
     "end_time": "2021-04-13T15:45:36.721472",
     "exception": false,
     "start_time": "2021-04-13T15:42:08.304693",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benchmark execution:  1 \n",
      "\n",
      "[------------- Batched dot --------------]\n",
      "                    |  mul/sum  |    bmm  \n",
      "1 threads: -------------------------------\n",
      "      [512, 512]    |    125.3  |    923.9\n",
      "      [1024, 1024]  |    587.5  |   3661.0\n",
      "      [2048, 2048]  |   4758.0  |  14325.8\n",
      "      [4096, 4096]  |  48614.0  |  56336.2\n",
      "      [5120, 5120]  |  77514.7  |  87857.0\n",
      "2 threads: -------------------------------\n",
      "      [512, 512]    |     57.7  |    483.7\n",
      "      [1024, 1024]  |    317.8  |   1853.4\n",
      "      [2048, 2048]  |   2361.1  |   7247.8\n",
      "      [4096, 4096]  |  27958.4  |  28501.6\n",
      "      [5120, 5120]  |  46861.4  |  46678.7\n",
      "3 threads: -------------------------------\n",
      "      [512, 512]    |     94.2  |    347.8\n",
      "      [1024, 1024]  |    402.3  |   1306.0\n",
      "      [2048, 2048]  |   2730.7  |   5057.1\n",
      "      [4096, 4096]  |  28783.1  |  19682.8\n",
      "      [5120, 5120]  |  43937.8  |  30589.1\n",
      "4 threads: -------------------------------\n",
      "      [512, 512]    |     65.0  |    286.3\n",
      "      [1024, 1024]  |    283.6  |   1026.9\n",
      "      [2048, 2048]  |   1873.8  |   3857.8\n",
      "      [4096, 4096]  |  23113.9  |  15044.9\n",
      "      [5120, 5120]  |  35103.4  |  23052.4\n",
      "\n",
      "Times are in microseconds (us).\n",
      "\n",
      "Benchmark execution:  2 \n",
      "\n",
      "[------------- Batched dot --------------]\n",
      "                    |  mul/sum  |    bmm  \n",
      "1 threads: -------------------------------\n",
      "      [512, 512]    |    125.1  |    922.7\n",
      "      [1024, 1024]  |    593.1  |   3657.3\n",
      "      [2048, 2048]  |   4857.5  |  14200.3\n",
      "      [4096, 4096]  |  48654.8  |  56513.0\n",
      "      [5120, 5120]  |  75706.9  |  87984.9\n",
      "2 threads: -------------------------------\n",
      "      [512, 512]    |     60.0  |    474.8\n",
      "      [1024, 1024]  |    304.0  |   1872.0\n",
      "      [2048, 2048]  |   2181.9  |   7245.4\n",
      "      [4096, 4096]  |  27908.8  |  28385.9\n",
      "      [5120, 5120]  |  43505.7  |  44148.0\n",
      "3 threads: -------------------------------\n",
      "      [512, 512]    |     91.1  |    350.3\n",
      "      [1024, 1024]  |    375.5  |   1332.1\n",
      "      [2048, 2048]  |   2784.8  |   5024.0\n",
      "      [4096, 4096]  |  28061.7  |  19641.6\n",
      "      [5120, 5120]  |  43335.9  |  30522.1\n",
      "4 threads: -------------------------------\n",
      "      [512, 512]    |     61.0  |    274.6\n",
      "      [1024, 1024]  |    279.3  |   1009.5\n",
      "      [2048, 2048]  |   1737.5  |   3879.1\n",
      "      [4096, 4096]  |  22177.7  |  14781.0\n",
      "      [5120, 5120]  |  34033.8  |  22899.3\n",
      "\n",
      "Times are in microseconds (us).\n",
      "\n",
      "Benchmark execution:  3 \n",
      "\n",
      "[------------- Batched dot --------------]\n",
      "                    |  mul/sum  |    bmm  \n",
      "1 threads: -------------------------------\n",
      "      [512, 512]    |    129.5  |    921.1\n",
      "      [1024, 1024]  |    603.0  |   3653.9\n",
      "      [2048, 2048]  |   4774.2  |  14199.3\n",
      "      [4096, 4096]  |  49101.2  |  56433.5\n",
      "      [5120, 5120]  |  75610.9  |  88228.8\n",
      "2 threads: -------------------------------\n",
      "      [512, 512]    |     58.8  |    474.7\n",
      "      [1024, 1024]  |    297.3  |   1860.4\n",
      "      [2048, 2048]  |   2247.1  |   7237.7\n",
      "      [4096, 4096]  |  27897.0  |  28407.2\n",
      "      [5120, 5120]  |  43060.3  |  44286.2\n",
      "3 threads: -------------------------------\n",
      "      [512, 512]    |     92.1  |    343.8\n",
      "      [1024, 1024]  |    373.8  |   1303.6\n",
      "      [2048, 2048]  |   2588.6  |   5033.1\n",
      "      [4096, 4096]  |  28151.0  |  19585.9\n",
      "      [5120, 5120]  |  43589.2  |  30349.0\n",
      "4 threads: -------------------------------\n",
      "      [512, 512]    |     62.5  |    266.7\n",
      "      [1024, 1024]  |    276.1  |   1037.9\n",
      "      [2048, 2048]  |   1817.1  |   3862.5\n",
      "      [4096, 4096]  |  22151.0  |  14783.5\n",
      "      [5120, 5120]  |  34367.4  |  23314.4\n",
      "\n",
      "Times are in microseconds (us).\n",
      "\n",
      "Benchmark execution:  4 \n",
      "\n",
      "[------------- Batched dot --------------]\n",
      "                    |  mul/sum  |    bmm  \n",
      "1 threads: -------------------------------\n",
      "      [512, 512]    |    128.7  |    922.9\n",
      "      [1024, 1024]  |    583.0  |   3644.9\n",
      "      [2048, 2048]  |   4653.5  |  14294.1\n",
      "      [4096, 4096]  |  49147.8  |  56178.4\n",
      "      [5120, 5120]  |  75456.3  |  87684.8\n",
      "2 threads: -------------------------------\n",
      "      [512, 512]    |     59.3  |    479.1\n",
      "      [1024, 1024]  |    297.0  |   1864.5\n",
      "      [2048, 2048]  |   2115.8  |   7214.1\n",
      "      [4096, 4096]  |  27936.3  |  28344.5\n",
      "      [5120, 5120]  |  43245.8  |  45663.3\n",
      "3 threads: -------------------------------\n",
      "      [512, 512]    |     92.4  |    356.9\n",
      "      [1024, 1024]  |    389.4  |   1296.1\n",
      "      [2048, 2048]  |   2616.5  |   5046.1\n",
      "      [4096, 4096]  |  28221.3  |  19778.5\n",
      "      [5120, 5120]  |  44180.0  |  30489.5\n",
      "4 threads: -------------------------------\n",
      "      [512, 512]    |     64.3  |    268.5\n",
      "      [1024, 1024]  |    298.0  |   1022.8\n",
      "      [2048, 2048]  |   1791.5  |   3832.9\n",
      "      [4096, 4096]  |  22323.3  |  14822.2\n",
      "      [5120, 5120]  |  34417.7  |  23160.7\n",
      "\n",
      "Times are in microseconds (us).\n",
      "\n",
      "Benchmark execution:  5 \n",
      "\n",
      "[------------- Batched dot --------------]\n",
      "                    |  mul/sum  |    bmm  \n",
      "1 threads: -------------------------------\n",
      "      [512, 512]    |    129.5  |    922.8\n",
      "      [1024, 1024]  |    590.1  |   3646.3\n",
      "      [2048, 2048]  |   4710.2  |  14154.5\n",
      "      [4096, 4096]  |  48997.1  |  56463.9\n",
      "      [5120, 5120]  |  75908.9  |  88337.9\n",
      "2 threads: -------------------------------\n",
      "      [512, 512]    |     60.0  |    476.7\n",
      "      [1024, 1024]  |    298.9  |   1848.5\n",
      "      [2048, 2048]  |   2085.8  |   7215.2\n",
      "      [4096, 4096]  |  31967.8  |  28317.8\n",
      "      [5120, 5120]  |  43123.4  |  44227.6\n",
      "3 threads: -------------------------------\n",
      "      [512, 512]    |     92.0  |    345.6\n",
      "      [1024, 1024]  |    394.5  |   1289.8\n",
      "      [2048, 2048]  |   2493.7  |   5018.4\n",
      "      [4096, 4096]  |  28127.1  |  19834.2\n",
      "      [5120, 5120]  |  43500.5  |  30370.5\n",
      "4 threads: -------------------------------\n",
      "      [512, 512]    |     63.1  |    268.0\n",
      "      [1024, 1024]  |    276.7  |    992.3\n",
      "      [2048, 2048]  |   1849.1  |   4070.2\n",
      "      [4096, 4096]  |  22777.8  |  14758.8\n",
      "      [5120, 5120]  |  34075.4  |  22886.1\n",
      "\n",
      "Times are in microseconds (us).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#The limit dimension of the sizes is with matrix of 100000x100000. It is running out of memory with that sizes\n",
    "sizes = [512,1024,2048,4096,5120]\n",
    "threads = range(1,num_threads+1)\n",
    "compares = []\n",
    "\n",
    "#The benchmark execute 5 times to gather data and afterwards \n",
    "for i in range(0,5):\n",
    "    print(\"Benchmark execution: \",i+1, \"\\n\")\n",
    "    compares.insert(i,benchMark(sizes,threads))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "heavy-concert",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-13T15:45:36.749175Z",
     "iopub.status.busy": "2021-04-13T15:45:36.748249Z",
     "iopub.status.idle": "2021-04-13T15:45:36.867511Z",
     "shell.execute_reply": "2021-04-13T15:45:36.868032Z"
    },
    "papermill": {
     "duration": 0.138967,
     "end_time": "2021-04-13T15:45:36.868226",
     "exception": false,
     "start_time": "2021-04-13T15:45:36.729259",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Generate a file.out with the results.\n",
    "#Benchmark from pytorch just generate a print from the sdtout, so we need to change the stdout to write it in a file.\n",
    "import sys\n",
    "\n",
    "original_stdout = sys.stdout # Save a reference to the original standard output\n",
    "\n",
    "with open('output_benchmark.out', 'w') as file:\n",
    "    sys.stdout = file # Change the standard output to the file we created.\n",
    "    i=1\n",
    "    for compare in compares:\n",
    "        print(\"Benchmark execution: \",i, \"\\n\")\n",
    "        compare.print()\n",
    "        i += 1\n",
    "    sys.stdout = original_stdout # Reset the standard output to its original value\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 217.431624,
   "end_time": "2021-04-13T15:45:37.686905",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-04-13T15:42:00.255281",
   "version": "2.3.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
