{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "suffering-border",
   "metadata": {
    "papermill": {
     "duration": 0.008359,
     "end_time": "2021-04-27T15:48:29.949285",
     "exception": false,
     "start_time": "2021-04-27T15:48:29.940926",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Benchmark for TPU using pytorch\n",
    "\n",
    "This code is going to do some computational test about the performance that a TPU can obtain. It's an adaptation from my previuous benchmarks using pytorch. However, the script to use pytorch-xla (the module that uses the TPU) it's only available to use with pytorch 1.6, it's not available to use it with current version (1.7), so, the BenchMark module from pytorch it's not included and it has to be replaced it by using the timeit module.\n",
    "\n",
    "Using timeit module made that executions can have a warmp up delay of a 2 us approximately. Besides, there's my own method for timing, and it'is going to be used to analyse the timeit library from pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "juvenile-gazette",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-27T15:48:29.992831Z",
     "iopub.status.busy": "2021-04-27T15:48:29.978270Z",
     "iopub.status.idle": "2021-04-27T15:49:49.210958Z",
     "shell.execute_reply": "2021-04-27T15:49:49.210198Z"
    },
    "papermill": {
     "duration": 79.25417,
     "end_time": "2021-04-27T15:49:49.211152",
     "exception": false,
     "start_time": "2021-04-27T15:48:29.956982",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\r\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\r\n",
      "100  5116  100  5116    0     0  63160      0 --:--:-- --:--:-- --:--:-- 63160\r\n",
      "Updating... This may take around 2 minutes.\r\n",
      "Updating TPU runtime to pytorch-dev20200515 ...\r\n",
      "Found existing installation: torch 1.7.0\r\n",
      "Uninstalling torch-1.7.0:\r\n",
      "Done updating TPU runtime\r\n",
      "  Successfully uninstalled torch-1.7.0\r\n",
      "Found existing installation: torchvision 0.8.1\r\n",
      "Uninstalling torchvision-0.8.1:\r\n",
      "  Successfully uninstalled torchvision-0.8.1\r\n",
      "Copying gs://tpu-pytorch/wheels/torch-nightly+20200515-cp37-cp37m-linux_x86_64.whl...\r\n",
      "\r\n",
      "Operation completed over 1 objects/91.0 MiB.                                     \r\n",
      "Copying gs://tpu-pytorch/wheels/torch_xla-nightly+20200515-cp37-cp37m-linux_x86_64.whl...\r\n",
      "\r\n",
      "Operation completed over 1 objects/119.5 MiB.                                    \r\n",
      "Copying gs://tpu-pytorch/wheels/torchvision-nightly+20200515-cp37-cp37m-linux_x86_64.whl...\r\n",
      "\r\n",
      "Operation completed over 1 objects/2.3 MiB.                                      \r\n",
      "Processing ./torch-nightly+20200515-cp37-cp37m-linux_x86_64.whl\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torch==nightly+20200515) (1.19.5)\r\n",
      "Requirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from torch==nightly+20200515) (0.18.2)\r\n",
      "Installing collected packages: torch\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "fastai 2.3.0 requires torchvision<0.9,>=0.8, which is not installed.\r\n",
      "easyocr 1.3.0.1 requires torchvision>=0.5, which is not installed.\r\n",
      "allennlp 2.3.0 requires torchvision<0.10.0,>=0.8.1, which is not installed.\r\n",
      "kornia 0.5.0 requires torch>=1.6.0, but you have torch 1.6.0a0+bf2bbd9 which is incompatible.\r\n",
      "fastai 2.3.0 requires torch<1.8,>=1.7.0, but you have torch 1.6.0a0+bf2bbd9 which is incompatible.\r\n",
      "allennlp 2.3.0 requires torch<1.9.0,>=1.6.0, but you have torch 1.6.0a0+bf2bbd9 which is incompatible.\u001b[0m\r\n",
      "Successfully installed torch-1.6.0a0+bf2bbd9\r\n",
      "Processing ./torch_xla-nightly+20200515-cp37-cp37m-linux_x86_64.whl\r\n",
      "Installing collected packages: torch-xla\r\n",
      "Successfully installed torch-xla-1.6+2b2085a\r\n",
      "Processing ./torchvision-nightly+20200515-cp37-cp37m-linux_x86_64.whl\r\n",
      "Requirement already satisfied: pillow>=4.1.1 in /opt/conda/lib/python3.7/site-packages (from torchvision==nightly+20200515) (7.2.0)\r\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.7/site-packages (from torchvision==nightly+20200515) (1.6.0a0+bf2bbd9)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torchvision==nightly+20200515) (1.19.5)\r\n",
      "Requirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from torch->torchvision==nightly+20200515) (0.18.2)\r\n",
      "Installing collected packages: torchvision\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "fastai 2.3.0 requires torch<1.8,>=1.7.0, but you have torch 1.6.0a0+bf2bbd9 which is incompatible.\r\n",
      "fastai 2.3.0 requires torchvision<0.9,>=0.8, but you have torchvision 0.7.0a0+a6073f0 which is incompatible.\r\n",
      "allennlp 2.3.0 requires torch<1.9.0,>=1.6.0, but you have torch 1.6.0a0+bf2bbd9 which is incompatible.\r\n",
      "allennlp 2.3.0 requires torchvision<0.10.0,>=0.8.1, but you have torchvision 0.7.0a0+a6073f0 which is incompatible.\u001b[0m\r\n",
      "Successfully installed torchvision-0.7.0a0+a6073f0\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "The following NEW packages will be installed:\r\n",
      "  libomp5 libopenblas-dev\r\n",
      "0 upgraded, 2 newly installed, 0 to remove and 15 not upgraded.\r\n",
      "Need to get 4094 kB of archives.\r\n",
      "After this operation, 54.2 MB of additional disk space will be used.\r\n",
      "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libopenblas-dev amd64 0.2.20+ds-4 [3860 kB]\r\n",
      "Get:2 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libomp5 amd64 5.0.1-1 [234 kB]\r\n",
      "Fetched 4094 kB in 1s (3024 kB/s)\r\n",
      "debconf: delaying package configuration, since apt-utils is not installed\r\n",
      "Selecting previously unselected package libopenblas-dev:amd64.\r\n",
      "(Reading database ... 95327 files and directories currently installed.)\r\n",
      "Preparing to unpack .../libopenblas-dev_0.2.20+ds-4_amd64.deb ...\r\n",
      "Unpacking libopenblas-dev:amd64 (0.2.20+ds-4) ...\r\n",
      "Selecting previously unselected package libomp5:amd64.\r\n",
      "Preparing to unpack .../libomp5_5.0.1-1_amd64.deb ...\r\n",
      "Unpacking libomp5:amd64 (5.0.1-1) ...\r\n",
      "Setting up libomp5:amd64 (5.0.1-1) ...\r\n",
      "Setting up libopenblas-dev:amd64 (0.2.20+ds-4) ...\r\n",
      "update-alternatives: using /usr/lib/x86_64-linux-gnu/openblas/libblas.so to provide /usr/lib/x86_64-linux-gnu/libblas.so (libblas.so-x86_64-linux-gnu) in auto mode\r\n",
      "update-alternatives: using /usr/lib/x86_64-linux-gnu/openblas/liblapack.so to provide /usr/lib/x86_64-linux-gnu/liblapack.so (liblapack.so-x86_64-linux-gnu) in auto mode\r\n",
      "Processing triggers for libc-bin (2.27-3ubuntu1.4) ...\r\n",
      "Collecting openpyxl\r\n",
      "  Downloading openpyxl-3.0.7-py2.py3-none-any.whl (243 kB)\r\n",
      "\u001b[K     |████████████████████████████████| 243 kB 2.9 MB/s \r\n",
      "\u001b[?25hCollecting et-xmlfile\r\n",
      "  Downloading et_xmlfile-1.1.0-py3-none-any.whl (4.7 kB)\r\n",
      "Installing collected packages: et-xmlfile, openpyxl\r\n",
      "Successfully installed et-xmlfile-1.1.0 openpyxl-3.0.7\r\n"
     ]
    }
   ],
   "source": [
    "!curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\n",
    "!python pytorch-xla-env-setup.py  --apt-packages libomp5 libopenblas-dev # --version=pytorch-1.8\n",
    "!pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "thrown-cylinder",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-27T15:49:49.278615Z",
     "iopub.status.busy": "2021-04-27T15:49:49.277558Z",
     "iopub.status.idle": "2021-04-27T15:49:49.836977Z",
     "shell.execute_reply": "2021-04-27T15:49:49.836103Z"
    },
    "papermill": {
     "duration": 0.595499,
     "end_time": "2021-04-27T15:49:49.837159",
     "exception": false,
     "start_time": "2021-04-27T15:49:49.241660",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6.0a0+bf2bbd9\n"
     ]
    }
   ],
   "source": [
    "# imports pytorch\n",
    "import torch\n",
    "\n",
    "print(torch.__version__)\n",
    "\n",
    "# imports the torch_xla package\n",
    "import torch_xla\n",
    "import torch_xla.core.xla_model as xm\n",
    "import platform\n",
    "import os\n",
    "#Importing Libraries needed for use torch\n",
    "import timeit\n",
    "#import torch.utils.benchmark as benchmark #torch_xla it is not compatible with 1.7, where it is the benchmark library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "hourly-balance",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-27T15:49:49.906794Z",
     "iopub.status.busy": "2021-04-27T15:49:49.905877Z",
     "iopub.status.idle": "2021-04-27T15:49:49.908567Z",
     "shell.execute_reply": "2021-04-27T15:49:49.909006Z"
    },
    "papermill": {
     "duration": 0.040628,
     "end_time": "2021-04-27T15:49:49.909199",
     "exception": false,
     "start_time": "2021-04-27T15:49:49.868571",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Functions obtained from Torch Webpages por PyTorch Benchmarks\n",
    "def batched_dot_mul_sum(a, b):\n",
    "    '''Computes batched dot by multiplying and summing'''\n",
    "    return a.mul(b).sum(-1)\n",
    "\n",
    "\n",
    "def batched_dot_bmm(a, b):\n",
    "    '''Computes batched dot by reducing to bmm'''\n",
    "    a = a.reshape(-1, 1, a.shape[-1])\n",
    "    b = b.reshape(-1, b.shape[-1], 1)\n",
    "    return torch.bmm(a, b).flatten(-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "worth-least",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-27T15:49:49.979085Z",
     "iopub.status.busy": "2021-04-27T15:49:49.978170Z",
     "iopub.status.idle": "2021-04-27T15:49:49.980952Z",
     "shell.execute_reply": "2021-04-27T15:49:49.981500Z"
    },
    "papermill": {
     "duration": 0.042159,
     "end_time": "2021-04-27T15:49:49.981768",
     "exception": false,
     "start_time": "2021-04-27T15:49:49.939609",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def benchMark(sizes,dev):   \n",
    "    for n in sizes:\n",
    "        x = torch.ones((n, n))\n",
    "        x = x.to(device=dev)\n",
    "        t0 = timeit.Timer(\n",
    "        stmt='batched_dot_mul_sum(x, x)',\n",
    "        setup='from __main__ import batched_dot_mul_sum',\n",
    "        globals={'x': x})\n",
    "\n",
    "        t1 = timeit.Timer(\n",
    "        stmt='batched_dot_bmm(x, x)',\n",
    "        setup='from __main__ import batched_dot_bmm',\n",
    "        globals={'x': x})\n",
    "\n",
    "        print('size of square matrix: ',n)\n",
    "        print(f'mul_sum(x, x):  {t0.timeit(5) / 100 * 1e6:>5.1f} us')\n",
    "        print(f'bmm(x, x):      {t1.timeit(5) / 100 * 1e6:>5.1f} us\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "recreational-championship",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-27T15:49:58.338850Z",
     "iopub.status.busy": "2021-04-27T15:49:58.337242Z",
     "iopub.status.idle": "2021-04-27T15:50:38.339794Z",
     "shell.execute_reply": "2021-04-27T15:50:38.340707Z"
    },
    "papermill": {
     "duration": 48.328386,
     "end_time": "2021-04-27T15:50:38.340972",
     "exception": false,
     "start_time": "2021-04-27T15:49:50.012586",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benchmark execution:  1 \n",
      "\n",
      "size of square matrix:  512\n",
      "mul_sum(x, x):    7.7 us\n",
      "bmm(x, x):        4.4 us\n",
      "\n",
      "size of square matrix:  1024\n",
      "mul_sum(x, x):    2.8 us\n",
      "bmm(x, x):        2.5 us\n",
      "\n",
      "size of square matrix:  2048\n",
      "mul_sum(x, x):    8.0 us\n",
      "bmm(x, x):        6.2 us\n",
      "\n",
      "size of square matrix:  4096\n",
      "mul_sum(x, x):    7.0 us\n",
      "bmm(x, x):        5.0 us\n",
      "\n",
      "size of square matrix:  8192\n",
      "mul_sum(x, x):    9.3 us\n",
      "bmm(x, x):        5.4 us\n",
      "\n",
      "size of square matrix:  16384\n",
      "mul_sum(x, x):   10.7 us\n",
      "bmm(x, x):        4.3 us\n",
      "\n",
      "Benchmark execution:  2 \n",
      "\n",
      "size of square matrix:  512\n",
      "mul_sum(x, x):    5.6 us\n",
      "bmm(x, x):        3.3 us\n",
      "\n",
      "size of square matrix:  1024\n",
      "mul_sum(x, x):    6.4 us\n",
      "bmm(x, x):        4.8 us\n",
      "\n",
      "size of square matrix:  2048\n",
      "mul_sum(x, x):    5.5 us\n",
      "bmm(x, x):        3.5 us\n",
      "\n",
      "size of square matrix:  4096\n",
      "mul_sum(x, x):    6.2 us\n",
      "bmm(x, x):        4.7 us\n",
      "\n",
      "size of square matrix:  8192\n",
      "mul_sum(x, x):    8.3 us\n",
      "bmm(x, x):        6.1 us\n",
      "\n",
      "size of square matrix:  16384\n",
      "mul_sum(x, x):    1.4 us\n",
      "bmm(x, x):       12.1 us\n",
      "\n",
      "Benchmark execution:  3 \n",
      "\n",
      "size of square matrix:  512\n",
      "mul_sum(x, x):    5.6 us\n",
      "bmm(x, x):        3.8 us\n",
      "\n",
      "size of square matrix:  1024\n",
      "mul_sum(x, x):    7.8 us\n",
      "bmm(x, x):        4.8 us\n",
      "\n",
      "size of square matrix:  2048\n",
      "mul_sum(x, x):    6.2 us\n",
      "bmm(x, x):        5.3 us\n",
      "\n",
      "size of square matrix:  4096\n",
      "mul_sum(x, x):    6.0 us\n",
      "bmm(x, x):        5.2 us\n",
      "\n",
      "size of square matrix:  8192\n",
      "mul_sum(x, x):    1.3 us\n",
      "bmm(x, x):       10.9 us\n",
      "\n",
      "size of square matrix:  16384\n",
      "mul_sum(x, x):    7.2 us\n",
      "bmm(x, x):        5.0 us\n",
      "\n",
      "Benchmark execution:  4 \n",
      "\n",
      "size of square matrix:  512\n",
      "mul_sum(x, x):    4.6 us\n",
      "bmm(x, x):        3.9 us\n",
      "\n",
      "size of square matrix:  1024\n",
      "mul_sum(x, x):    5.7 us\n",
      "bmm(x, x):        3.8 us\n",
      "\n",
      "size of square matrix:  2048\n",
      "mul_sum(x, x):    5.8 us\n",
      "bmm(x, x):        2.6 us\n",
      "\n",
      "size of square matrix:  4096\n",
      "mul_sum(x, x):    3.0 us\n",
      "bmm(x, x):        2.0 us\n",
      "\n",
      "size of square matrix:  8192\n",
      "mul_sum(x, x):    8.3 us\n",
      "bmm(x, x):        4.3 us\n",
      "\n",
      "size of square matrix:  16384\n",
      "mul_sum(x, x):    1.7 us\n",
      "bmm(x, x):        2.1 us\n",
      "\n",
      "Benchmark execution:  5 \n",
      "\n",
      "size of square matrix:  512\n",
      "mul_sum(x, x):    1.5 us\n",
      "bmm(x, x):        2.4 us\n",
      "\n",
      "size of square matrix:  1024\n",
      "mul_sum(x, x):    1.4 us\n",
      "bmm(x, x):        2.6 us\n",
      "\n",
      "size of square matrix:  2048\n",
      "mul_sum(x, x):    1.5 us\n",
      "bmm(x, x):        2.7 us\n",
      "\n",
      "size of square matrix:  4096\n",
      "mul_sum(x, x):    7.3 us\n",
      "bmm(x, x):        5.7 us\n",
      "\n",
      "size of square matrix:  8192\n",
      "mul_sum(x, x):    1.5 us\n",
      "bmm(x, x):        2.2 us\n",
      "\n",
      "size of square matrix:  16384\n",
      "mul_sum(x, x):    9.5 us\n",
      "bmm(x, x):        5.8 us\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dev = xm.xla_device()\n",
    "sizes = [512,1024,2048,4096,8192,16384] # maximun size withou running out memory -> 32768\n",
    "\n",
    "for i in range(0,5):\n",
    "        print(\"Benchmark execution: \",i+1, \"\\n\")\n",
    "        benchMark(sizes,dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "center-collaboration",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-27T15:50:38.433443Z",
     "iopub.status.busy": "2021-04-27T15:50:38.432266Z",
     "iopub.status.idle": "2021-04-27T15:50:38.437450Z",
     "shell.execute_reply": "2021-04-27T15:50:38.436125Z"
    },
    "papermill": {
     "duration": 0.056997,
     "end_time": "2021-04-27T15:50:38.437756",
     "exception": false,
     "start_time": "2021-04-27T15:50:38.380759",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def ownBenchmark(sizes,writerCSV,operation):\n",
    "    dev = xm.xla_device()\n",
    "    for i in range(0,5):\n",
    "        print(\"\\nBenchmark execution for \",operation,\": \",i+1, \"\\n\")\n",
    "        for n in sizes:\n",
    "            timeInit = time.time()\n",
    "            xCPU = torch.ones(n, n)\n",
    "            xTPU = xCPU.to(device=dev)\n",
    "            if(operation == \"mul_sum\"):\n",
    "                batched_dot_mul_sum(xTPU,xTPU)\n",
    "            else:\n",
    "                batched_dot_bmm(xTPU,xTPU)\n",
    "            timeFinish = time.time()\n",
    "            print(f\"size matrix [{n}] -> {(timeFinish - timeInit):0.8f} s\")\n",
    "            writer.writerow([operation, n, i+1,(timeFinish - timeInit)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "banner-stand",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-27T15:50:38.517914Z",
     "iopub.status.busy": "2021-04-27T15:50:38.517050Z",
     "iopub.status.idle": "2021-04-27T15:51:47.428604Z",
     "shell.execute_reply": "2021-04-27T15:51:47.429205Z"
    },
    "papermill": {
     "duration": 68.953396,
     "end_time": "2021-04-27T15:51:47.429483",
     "exception": false,
     "start_time": "2021-04-27T15:50:38.476087",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Benchmark execution for  mul_sum :  1 \n",
      "\n",
      "size matrix [512] -> 0.00530362 s\n",
      "size matrix [1024] -> 0.01515794 s\n",
      "size matrix [2048] -> 0.04899144 s\n",
      "size matrix [4096] -> 0.32499886 s\n",
      "size matrix [8192] -> 1.30783510 s\n",
      "size matrix [16384] -> 5.07148576 s\n",
      "\n",
      "Benchmark execution for  mul_sum :  2 \n",
      "\n",
      "size matrix [512] -> 0.04917693 s\n",
      "size matrix [1024] -> 0.01009464 s\n",
      "size matrix [2048] -> 0.04144573 s\n",
      "size matrix [4096] -> 0.35329938 s\n",
      "size matrix [8192] -> 1.37029552 s\n",
      "size matrix [16384] -> 4.78269672 s\n",
      "\n",
      "Benchmark execution for  mul_sum :  3 \n",
      "\n",
      "size matrix [512] -> 0.05050397 s\n",
      "size matrix [1024] -> 0.01043797 s\n",
      "size matrix [2048] -> 0.05476999 s\n",
      "size matrix [4096] -> 0.31031942 s\n",
      "size matrix [8192] -> 1.27683711 s\n",
      "size matrix [16384] -> 5.03634143 s\n",
      "\n",
      "Benchmark execution for  mul_sum :  4 \n",
      "\n",
      "size matrix [512] -> 0.05379534 s\n",
      "size matrix [1024] -> 0.00998259 s\n",
      "size matrix [2048] -> 0.04655671 s\n",
      "size matrix [4096] -> 0.28967881 s\n",
      "size matrix [8192] -> 1.26316905 s\n",
      "size matrix [16384] -> 4.80745459 s\n",
      "\n",
      "Benchmark execution for  mul_sum :  5 \n",
      "\n",
      "size matrix [512] -> 0.05563688 s\n",
      "size matrix [1024] -> 0.01031971 s\n",
      "size matrix [2048] -> 0.05683303 s\n",
      "size matrix [4096] -> 0.30289268 s\n",
      "size matrix [8192] -> 1.17276955 s\n",
      "size matrix [16384] -> 5.05734849 s\n",
      "\n",
      "Benchmark execution for  bmm :  1 \n",
      "\n",
      "size matrix [512] -> 0.00636268 s\n",
      "size matrix [1024] -> 0.01025939 s\n",
      "size matrix [2048] -> 0.03263831 s\n",
      "size matrix [4096] -> 0.28445101 s\n",
      "size matrix [8192] -> 1.28140402 s\n",
      "size matrix [16384] -> 4.85165763 s\n",
      "\n",
      "Benchmark execution for  bmm :  2 \n",
      "\n",
      "size matrix [512] -> 0.05800009 s\n",
      "size matrix [1024] -> 0.01191092 s\n",
      "size matrix [2048] -> 0.04867911 s\n",
      "size matrix [4096] -> 0.31288099 s\n",
      "size matrix [8192] -> 1.31376123 s\n",
      "size matrix [16384] -> 5.44838524 s\n",
      "\n",
      "Benchmark execution for  bmm :  3 \n",
      "\n",
      "size matrix [512] -> 0.06039357 s\n",
      "size matrix [1024] -> 0.01102710 s\n",
      "size matrix [2048] -> 0.04062700 s\n",
      "size matrix [4096] -> 0.34982252 s\n",
      "size matrix [8192] -> 1.42003870 s\n",
      "size matrix [16384] -> 5.10868573 s\n",
      "\n",
      "Benchmark execution for  bmm :  4 \n",
      "\n",
      "size matrix [512] -> 0.05450153 s\n",
      "size matrix [1024] -> 0.01260376 s\n",
      "size matrix [2048] -> 0.04009867 s\n",
      "size matrix [4096] -> 0.36378360 s\n",
      "size matrix [8192] -> 1.35944963 s\n",
      "size matrix [16384] -> 5.57263184 s\n",
      "\n",
      "Benchmark execution for  bmm :  5 \n",
      "\n",
      "size matrix [512] -> 0.08868814 s\n",
      "size matrix [1024] -> 0.01161838 s\n",
      "size matrix [2048] -> 0.05657506 s\n",
      "size matrix [4096] -> 0.56754541 s\n",
      "size matrix [8192] -> 1.47770000 s\n",
      "size matrix [16384] -> 5.28585315 s\n"
     ]
    }
   ],
   "source": [
    "#Now my own benchmark. With this i going to measure Speed ups and efficiencies. The pytorch benchmark give us too good results to be true...\n",
    "# We are going to use the library time from python and do the syncronizations to the gpu device\n",
    "import time #-> time.time() returns the time in seconds\n",
    "import csv #We are going to generate an csv with the results to work with pandas\n",
    "\n",
    "sizes = [512,1024,2048,4096,8192,16384] # maximun size withou running out memory -> 32768\n",
    "\n",
    "with open('results_tpu.csv', 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"operation\", \"sizeMatrix\", \"numberCase\",\"timeElpased\"])\n",
    "    ownBenchmark(sizes,writer,\"mul_sum\")\n",
    "    ownBenchmark(sizes,writer,\"bmm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "relative-class",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-27T15:51:47.550171Z",
     "iopub.status.busy": "2021-04-27T15:51:47.549405Z",
     "iopub.status.idle": "2021-04-27T15:51:47.906684Z",
     "shell.execute_reply": "2021-04-27T15:51:47.905723Z"
    },
    "papermill": {
     "duration": 0.422172,
     "end_time": "2021-04-27T15:51:47.906891",
     "exception": false,
     "start_time": "2021-04-27T15:51:47.484719",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 60 entries, 0 to 59\n",
      "Data columns (total 4 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   operation    60 non-null     object \n",
      " 1   sizeMatrix   60 non-null     int64  \n",
      " 2   numberCase   60 non-null     int64  \n",
      " 3   timeElpased  60 non-null     float64\n",
      "dtypes: float64(1), int64(2), object(1)\n",
      "memory usage: 2.0+ KB\n"
     ]
    }
   ],
   "source": [
    "#Generate the excel and giving a little of format\n",
    "#TODO include the calculate of FLOPS in excel/dataFrame\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"results_tpu.csv\")\n",
    "df.info()\n",
    "\n",
    "df_sorted = df.sort_values(by=[\"operation\",\"numberCase\"])\n",
    "\n",
    "df_sorted.to_excel(\"results_tpu_excel.xlsx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 209.025304,
   "end_time": "2021-04-27T15:51:49.854235",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-04-27T15:48:20.828931",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
