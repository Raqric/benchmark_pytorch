{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "level-pearl",
   "metadata": {
    "papermill": {
     "duration": 0.009215,
     "end_time": "2021-04-22T14:57:34.224429",
     "exception": false,
     "start_time": "2021-04-22T14:57:34.215214",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Benchmark for TPU using pytorch\n",
    "\n",
    "This code is going to do some computational test about the performance that a TPU can obtain. It's an adaptation from my previuous benchmarks using pytorch. However, the script to use pytorch-xla (the module that uses the TPU) it's only available to use with pytorch 1.6, it's not available to use it with current version (1.7), so, the BenchMark module from pytorch it's not included and it has to be replaced it by using the timeit module.\n",
    "\n",
    "Using timeit module made that executions can have a warmp up delay of a 2 us approximately. Besides, there's my own method for timing, and it'is going to be used to analyse the timeit library from pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "perfect-canberra",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-22T14:57:34.265158Z",
     "iopub.status.busy": "2021-04-22T14:57:34.252805Z",
     "iopub.status.idle": "2021-04-22T14:58:46.520458Z",
     "shell.execute_reply": "2021-04-22T14:58:46.519556Z"
    },
    "papermill": {
     "duration": 72.287849,
     "end_time": "2021-04-22T14:58:46.520643",
     "exception": false,
     "start_time": "2021-04-22T14:57:34.232794",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\r\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\r\n",
      "100  5116  100  5116    0     0  29572      0 --:--:-- --:--:-- --:--:-- 29572\r\n",
      "Updating... This may take around 2 minutes.\r\n",
      "Updating TPU runtime to pytorch-dev20200515 ...\r\n",
      "Found existing installation: torch 1.7.0\r\n",
      "Uninstalling torch-1.7.0:\r\n",
      "Done updating TPU runtime\r\n",
      "  Successfully uninstalled torch-1.7.0\r\n",
      "Found existing installation: torchvision 0.8.1\r\n",
      "Uninstalling torchvision-0.8.1:\r\n",
      "  Successfully uninstalled torchvision-0.8.1\r\n",
      "Copying gs://tpu-pytorch/wheels/torch-nightly+20200515-cp37-cp37m-linux_x86_64.whl...\r\n",
      "\r\n",
      "Operation completed over 1 objects/91.0 MiB.                                     \r\n",
      "Copying gs://tpu-pytorch/wheels/torch_xla-nightly+20200515-cp37-cp37m-linux_x86_64.whl...\r\n",
      "\r\n",
      "Operation completed over 1 objects/119.5 MiB.                                    \r\n",
      "Copying gs://tpu-pytorch/wheels/torchvision-nightly+20200515-cp37-cp37m-linux_x86_64.whl...\r\n",
      "\r\n",
      "Operation completed over 1 objects/2.3 MiB.                                      \r\n",
      "Processing ./torch-nightly+20200515-cp37-cp37m-linux_x86_64.whl\r\n",
      "Requirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from torch==nightly+20200515) (0.18.2)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torch==nightly+20200515) (1.19.5)\r\n",
      "Installing collected packages: torch\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "fastai 2.3.0 requires torchvision<0.9,>=0.8, which is not installed.\r\n",
      "easyocr 1.3.0.1 requires torchvision>=0.5, which is not installed.\r\n",
      "allennlp 2.3.0 requires torchvision<0.10.0,>=0.8.1, which is not installed.\r\n",
      "kornia 0.5.0 requires torch>=1.6.0, but you have torch 1.6.0a0+bf2bbd9 which is incompatible.\r\n",
      "fastai 2.3.0 requires torch<1.8,>=1.7.0, but you have torch 1.6.0a0+bf2bbd9 which is incompatible.\r\n",
      "allennlp 2.3.0 requires torch<1.9.0,>=1.6.0, but you have torch 1.6.0a0+bf2bbd9 which is incompatible.\u001b[0m\r\n",
      "Successfully installed torch-1.6.0a0+bf2bbd9\r\n",
      "Processing ./torch_xla-nightly+20200515-cp37-cp37m-linux_x86_64.whl\r\n",
      "Installing collected packages: torch-xla\r\n",
      "Successfully installed torch-xla-1.6+2b2085a\r\n",
      "Processing ./torchvision-nightly+20200515-cp37-cp37m-linux_x86_64.whl\r\n",
      "Requirement already satisfied: pillow>=4.1.1 in /opt/conda/lib/python3.7/site-packages (from torchvision==nightly+20200515) (7.2.0)\r\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.7/site-packages (from torchvision==nightly+20200515) (1.6.0a0+bf2bbd9)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torchvision==nightly+20200515) (1.19.5)\r\n",
      "Requirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from torch->torchvision==nightly+20200515) (0.18.2)\r\n",
      "Installing collected packages: torchvision\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "fastai 2.3.0 requires torch<1.8,>=1.7.0, but you have torch 1.6.0a0+bf2bbd9 which is incompatible.\r\n",
      "fastai 2.3.0 requires torchvision<0.9,>=0.8, but you have torchvision 0.7.0a0+a6073f0 which is incompatible.\r\n",
      "allennlp 2.3.0 requires torch<1.9.0,>=1.6.0, but you have torch 1.6.0a0+bf2bbd9 which is incompatible.\r\n",
      "allennlp 2.3.0 requires torchvision<0.10.0,>=0.8.1, but you have torchvision 0.7.0a0+a6073f0 which is incompatible.\u001b[0m\r\n",
      "Successfully installed torchvision-0.7.0a0+a6073f0\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "The following NEW packages will be installed:\r\n",
      "  libomp5 libopenblas-dev\r\n",
      "0 upgraded, 2 newly installed, 0 to remove and 15 not upgraded.\r\n",
      "Need to get 4094 kB of archives.\r\n",
      "After this operation, 54.2 MB of additional disk space will be used.\r\n",
      "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libopenblas-dev amd64 0.2.20+ds-4 [3860 kB]\r\n",
      "Get:2 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libomp5 amd64 5.0.1-1 [234 kB]\r\n",
      "Fetched 4094 kB in 1s (3160 kB/s)\r\n",
      "debconf: delaying package configuration, since apt-utils is not installed\r\n",
      "Selecting previously unselected package libopenblas-dev:amd64.\r\n",
      "(Reading database ... 95327 files and directories currently installed.)\r\n",
      "Preparing to unpack .../libopenblas-dev_0.2.20+ds-4_amd64.deb ...\r\n",
      "Unpacking libopenblas-dev:amd64 (0.2.20+ds-4) ...\r\n",
      "Selecting previously unselected package libomp5:amd64.\r\n",
      "Preparing to unpack .../libomp5_5.0.1-1_amd64.deb ...\r\n",
      "Unpacking libomp5:amd64 (5.0.1-1) ...\r\n",
      "Setting up libomp5:amd64 (5.0.1-1) ...\r\n",
      "Setting up libopenblas-dev:amd64 (0.2.20+ds-4) ...\r\n",
      "update-alternatives: using /usr/lib/x86_64-linux-gnu/openblas/libblas.so to provide /usr/lib/x86_64-linux-gnu/libblas.so (libblas.so-x86_64-linux-gnu) in auto mode\r\n",
      "update-alternatives: using /usr/lib/x86_64-linux-gnu/openblas/liblapack.so to provide /usr/lib/x86_64-linux-gnu/liblapack.so (liblapack.so-x86_64-linux-gnu) in auto mode\r\n",
      "Processing triggers for libc-bin (2.27-3ubuntu1.4) ...\r\n"
     ]
    }
   ],
   "source": [
    "!curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\n",
    "!python pytorch-xla-env-setup.py  --apt-packages libomp5 libopenblas-dev # --version=pytorch-1.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "certain-graphics",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-22T14:58:46.581323Z",
     "iopub.status.busy": "2021-04-22T14:58:46.580371Z",
     "iopub.status.idle": "2021-04-22T14:58:47.210959Z",
     "shell.execute_reply": "2021-04-22T14:58:47.210008Z"
    },
    "papermill": {
     "duration": 0.664027,
     "end_time": "2021-04-22T14:58:47.211743",
     "exception": false,
     "start_time": "2021-04-22T14:58:46.547716",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6.0a0+bf2bbd9\n"
     ]
    }
   ],
   "source": [
    "# imports pytorch\n",
    "import torch\n",
    "\n",
    "print(torch.__version__)\n",
    "\n",
    "# imports the torch_xla package\n",
    "import torch_xla\n",
    "import torch_xla.core.xla_model as xm\n",
    "import platform\n",
    "import os\n",
    "#Importing Libraries needed for use torch\n",
    "import timeit\n",
    "#import torch.utils.benchmark as benchmark #torch_xla it is not compatible with 1.7, where it is the benchmark library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "alpine-batch",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-22T14:58:47.284967Z",
     "iopub.status.busy": "2021-04-22T14:58:47.284280Z",
     "iopub.status.idle": "2021-04-22T14:58:47.287707Z",
     "shell.execute_reply": "2021-04-22T14:58:47.287141Z"
    },
    "papermill": {
     "duration": 0.041092,
     "end_time": "2021-04-22T14:58:47.287857",
     "exception": false,
     "start_time": "2021-04-22T14:58:47.246765",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Functions obtained from Torch Webpages por PyTorch Benchmarks\n",
    "def batched_dot_mul_sum(a, b):\n",
    "    '''Computes batched dot by multiplying and summing'''\n",
    "    return a.mul(b).sum(-1)\n",
    "\n",
    "\n",
    "def batched_dot_bmm(a, b):\n",
    "    '''Computes batched dot by reducing to bmm'''\n",
    "    a = a.reshape(-1, 1, a.shape[-1])\n",
    "    b = b.reshape(-1, b.shape[-1], 1)\n",
    "    return torch.bmm(a, b).flatten(-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fluid-globe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-22T14:58:47.351266Z",
     "iopub.status.busy": "2021-04-22T14:58:47.350246Z",
     "iopub.status.idle": "2021-04-22T14:58:47.353530Z",
     "shell.execute_reply": "2021-04-22T14:58:47.352952Z"
    },
    "papermill": {
     "duration": 0.037907,
     "end_time": "2021-04-22T14:58:47.353672",
     "exception": false,
     "start_time": "2021-04-22T14:58:47.315765",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def benchMark(sizes,dev):   \n",
    "    for n in sizes:\n",
    "        x = torch.ones((n, n))\n",
    "        x = x.to(device=dev)\n",
    "        t0 = timeit.Timer(\n",
    "        stmt='batched_dot_mul_sum(x, x)',\n",
    "        setup='from __main__ import batched_dot_mul_sum',\n",
    "        globals={'x': x})\n",
    "\n",
    "        t1 = timeit.Timer(\n",
    "        stmt='batched_dot_bmm(x, x)',\n",
    "        setup='from __main__ import batched_dot_bmm',\n",
    "        globals={'x': x})\n",
    "\n",
    "        print('size of square matrix: ',n)\n",
    "        print(f'mul_sum(x, x):  {t0.timeit(5) / 100 * 1e6:>5.1f} us')\n",
    "        print(f'bmm(x, x):      {t1.timeit(5) / 100 * 1e6:>5.1f} us\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "chinese-documentation",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-22T14:58:47.424040Z",
     "iopub.status.busy": "2021-04-22T14:58:47.422988Z",
     "iopub.status.idle": "2021-04-22T14:58:47.508897Z",
     "shell.execute_reply": "2021-04-22T14:58:47.508322Z"
    },
    "papermill": {
     "duration": 0.127617,
     "end_time": "2021-04-22T14:58:47.509043",
     "exception": false,
     "start_time": "2021-04-22T14:58:47.381426",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benchmark execution:  1 \n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'sizes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-c81d070bec80>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Benchmark execution: \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0mbenchMark\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msizes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'sizes' is not defined"
     ]
    }
   ],
   "source": [
    "for i in range(0,5):\n",
    "        print(\"Benchmark execution: \",i+1, \"\\n\")\n",
    "        benchMark(sizes,dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "extreme-basis",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-22T14:58:54.985701Z",
     "iopub.status.busy": "2021-04-22T14:58:54.984800Z",
     "iopub.status.idle": "2021-04-22T14:59:29.575111Z",
     "shell.execute_reply": "2021-04-22T14:59:29.575658Z"
    },
    "papermill": {
     "duration": 42.038216,
     "end_time": "2021-04-22T14:59:29.575862",
     "exception": false,
     "start_time": "2021-04-22T14:58:47.537646",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Benchmark execution for batched_dot_mul_sum:  1 \n",
      "\n",
      "size matrix [512] -> 0.01723552 s\n",
      "size matrix [1024] -> 0.03187752 s\n",
      "size matrix [2048] -> 0.10471439 s\n",
      "size matrix [4096] -> 0.46381640 s\n",
      "size matrix [8192] -> 1.52552986 s\n",
      "size matrix [16384] -> 5.70313144 s\n",
      "\n",
      "Benchmark execution for batched_dot_mul_sum:  2 \n",
      "\n",
      "size matrix [512] -> 0.04820681 s\n",
      "size matrix [1024] -> 0.01482964 s\n",
      "size matrix [2048] -> 0.05203986 s\n",
      "size matrix [4096] -> 0.30052972 s\n",
      "size matrix [8192] -> 1.18074107 s\n",
      "size matrix [16384] -> 5.41844082 s\n",
      "\n",
      "Benchmark execution for batched_dot_mul_sum:  3 \n",
      "\n",
      "size matrix [512] -> 0.04722190 s\n",
      "size matrix [1024] -> 0.01320314 s\n",
      "size matrix [2048] -> 0.05595207 s\n",
      "size matrix [4096] -> 0.29808450 s\n",
      "size matrix [8192] -> 1.28567433 s\n",
      "size matrix [16384] -> 4.82329321 s\n",
      "\n",
      "Benchmark execution for batched_dot_mul_sum:  4 \n",
      "\n",
      "size matrix [512] -> 0.04757476 s\n",
      "size matrix [1024] -> 0.01040030 s\n",
      "size matrix [2048] -> 0.03689814 s\n",
      "size matrix [4096] -> 0.30336070 s\n",
      "size matrix [8192] -> 1.27160001 s\n",
      "size matrix [16384] -> 5.08246827 s\n",
      "\n",
      "Benchmark execution for batched_dot_mul_sum:  5 \n",
      "\n",
      "size matrix [512] -> 0.04652119 s\n",
      "size matrix [1024] -> 0.01064157 s\n",
      "size matrix [2048] -> 0.03378153 s\n",
      "size matrix [4096] -> 0.29985189 s\n",
      "size matrix [8192] -> 1.28539705 s\n",
      "size matrix [16384] -> 4.76416445 s\n"
     ]
    }
   ],
   "source": [
    "#This block of code was used to debug a problem with FLOPs and timing because of pytorch benchmark\n",
    "#Pytorch Benchmark i belive calculates erroneusly the timings, it should be x10\n",
    "import sys\n",
    "import time #-> time.time() returns the time in seconds\n",
    "\n",
    "dev = xm.xla_device()\n",
    "sizes = [512,1024,2048,4096,8192,16384] # maximun size withou running out memory -> 32768\n",
    "\n",
    "#Firstly batched_dot_mul_sum\n",
    "for i in range(0,5):\n",
    "    print(\"\\nBenchmark execution for batched_dot_mul_sum: \",i+1, \"\\n\")\n",
    "    for n in sizes:\n",
    "        timeInit = time.time()\n",
    "\n",
    "        xCPU = torch.ones(n, n)\n",
    "        xTPU = xCPU.to(device=dev)\n",
    "\n",
    "        batched_dot_mul_sum(xTPU,xTPU)\n",
    "\n",
    "        timeFinish = time.time()\n",
    "\n",
    "        print(f\"size matrix [{n}] -> {(timeFinish - timeInit):0.8f} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "changing-inquiry",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-22T14:59:29.693082Z",
     "iopub.status.busy": "2021-04-22T14:59:29.649855Z",
     "iopub.status.idle": "2021-04-22T15:00:03.419149Z",
     "shell.execute_reply": "2021-04-22T15:00:03.419940Z"
    },
    "papermill": {
     "duration": 33.810056,
     "end_time": "2021-04-22T15:00:03.420210",
     "exception": false,
     "start_time": "2021-04-22T14:59:29.610154",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Benchmark execution for batched_dot_bmm:  1 \n",
      "\n",
      "size matrix [512] -> 0.04796410 s\n",
      "size matrix [1024] -> 0.02043056 s\n",
      "size matrix [2048] -> 0.04794312 s\n",
      "size matrix [4096] -> 0.30063081 s\n",
      "size matrix [8192] -> 1.27892423 s\n",
      "size matrix [16384] -> 5.13432431 s\n",
      "\n",
      "Benchmark execution for batched_dot_bmm:  2 \n",
      "\n",
      "size matrix [512] -> 0.05016899 s\n",
      "size matrix [1024] -> 0.01019764 s\n",
      "size matrix [2048] -> 0.05459046 s\n",
      "size matrix [4096] -> 0.30239129 s\n",
      "size matrix [8192] -> 1.27758646 s\n",
      "size matrix [16384] -> 4.99838758 s\n",
      "\n",
      "Benchmark execution for batched_dot_bmm:  3 \n",
      "\n",
      "size matrix [512] -> 0.04662132 s\n",
      "size matrix [1024] -> 0.01001620 s\n",
      "size matrix [2048] -> 0.05309319 s\n",
      "size matrix [4096] -> 0.30087042 s\n",
      "size matrix [8192] -> 1.26505852 s\n",
      "size matrix [16384] -> 5.12098169 s\n",
      "\n",
      "Benchmark execution for batched_dot_bmm:  4 \n",
      "\n",
      "size matrix [512] -> 0.04772997 s\n",
      "size matrix [1024] -> 0.01057267 s\n",
      "size matrix [2048] -> 0.03583956 s\n",
      "size matrix [4096] -> 0.36060619 s\n",
      "size matrix [8192] -> 1.29745913 s\n",
      "size matrix [16384] -> 4.82508254 s\n",
      "\n",
      "Benchmark execution for batched_dot_bmm:  5 \n",
      "\n",
      "size matrix [512] -> 0.05176306 s\n",
      "size matrix [1024] -> 0.01084089 s\n",
      "size matrix [2048] -> 0.06269598 s\n",
      "size matrix [4096] -> 0.31605792 s\n",
      "size matrix [8192] -> 1.27361941 s\n",
      "size matrix [16384] -> 5.10650587 s\n"
     ]
    }
   ],
   "source": [
    "#Now batched_dot_bmm\n",
    "for i in range(0,5):\n",
    "    print(\"\\nBenchmark execution for batched_dot_bmm: \",i+1, \"\\n\")\n",
    "    for n in sizes:\n",
    "        timeInit = time.time()\n",
    "\n",
    "        xCPU = torch.ones(n, n)\n",
    "        xTPU = xCPU.to(device=dev)\n",
    "        batched_dot_bmm(xTPU,xTPU)\n",
    "        \n",
    "        timeFinish = time.time()\n",
    "\n",
    "        print(f\"size matrix [{n}] -> {(timeFinish - timeInit):0.8f} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "senior-health",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-22T15:00:03.503229Z",
     "iopub.status.busy": "2021-04-22T15:00:03.502522Z",
     "iopub.status.idle": "2021-04-22T15:00:03.504576Z",
     "shell.execute_reply": "2021-04-22T15:00:03.505033Z"
    },
    "papermill": {
     "duration": 0.045441,
     "end_time": "2021-04-22T15:00:03.505232",
     "exception": false,
     "start_time": "2021-04-22T15:00:03.459791",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Generate a file.out with the results.\n",
    "#Benchmark from pytorch just generate a print from the sdtout, so we need to change the stdout to write it in a file.\n",
    "#import sys\n",
    "\n",
    "#original_stdout = sys.stdout # Save a reference to the original standard output\n",
    "\n",
    "#with open('output_benchmark.out', 'w') as file:\n",
    "#    sys.stdout = file # Change the standard output to the file we created.\n",
    "#    #The benchmark execute 5 times to gather data and afterwards \n",
    "#    for i in range(0,5):\n",
    "#        print(\"Benchmark execution: \",i+1, \"\\n\")\n",
    "#        benchMark(sizes,dev)\n",
    "\n",
    "#sys.stdout = original_stdout # Reset the standard output to its original value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "french-illustration",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-22T15:00:03.588255Z",
     "iopub.status.busy": "2021-04-22T15:00:03.587569Z",
     "iopub.status.idle": "2021-04-22T15:00:03.591126Z",
     "shell.execute_reply": "2021-04-22T15:00:03.590591Z"
    },
    "papermill": {
     "duration": 0.046645,
     "end_time": "2021-04-22T15:00:03.591314",
     "exception": false,
     "start_time": "2021-04-22T15:00:03.544669",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Printing the results\n",
    "#with open('output_benchmark.out', 'r') as file:\n",
    "#    for line in file.readlines():\n",
    "#        print(line)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 158.793465,
   "end_time": "2021-04-22T15:00:04.542010",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-04-22T14:57:25.748545",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
