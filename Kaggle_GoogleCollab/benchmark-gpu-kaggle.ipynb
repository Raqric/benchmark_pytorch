{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "synthetic-spirit",
   "metadata": {
    "papermill": {
     "duration": 0.007326,
     "end_time": "2021-04-23T16:54:29.261980",
     "exception": false,
     "start_time": "2021-04-23T16:54:29.254654",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    "# Benchmarking GPUs in Kaggle\n",
    "\n",
    "In this Kaggle notebook there is an adaptation from my Benchmark CPU to GPU using pytorch benchmark. The main method (benchmark) it change the input parameters, now it just needs the sizes to process. We are going to check the results and analyse them. Besides, there's my own method for timing, and it'is going to be used to analyse the timeit library from pytorch. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "guilty-dictionary",
   "metadata": {
    "papermill": {
     "duration": 0.00589,
     "end_time": "2021-04-23T16:54:29.274177",
     "exception": false,
     "start_time": "2021-04-23T16:54:29.268287",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## My CPU Benchmark adapted to GPU\n",
    "\n",
    "Pytorch has hard coded a block size of 256 threads. So there's only one execution per matrix size.\n",
    "\n",
    "One important advertisment! GPU accelerator has to be activated to use this notebook, if not, the notebook is not going to compile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "accessory-modification",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-23T16:54:29.303778Z",
     "iopub.status.busy": "2021-04-23T16:54:29.292926Z",
     "iopub.status.idle": "2021-04-23T16:54:41.257077Z",
     "shell.execute_reply": "2021-04-23T16:54:41.256431Z"
    },
    "papermill": {
     "duration": 11.976957,
     "end_time": "2021-04-23T16:54:41.257223",
     "exception": false,
     "start_time": "2021-04-23T16:54:29.280266",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openpyxl\r\n",
      "  Downloading openpyxl-3.0.7-py2.py3-none-any.whl (243 kB)\r\n",
      "\u001b[K     |████████████████████████████████| 243 kB 1.3 MB/s \r\n",
      "\u001b[?25hCollecting et-xmlfile\r\n",
      "  Downloading et_xmlfile-1.0.1.tar.gz (8.4 kB)\r\n",
      "Building wheels for collected packages: et-xmlfile\r\n",
      "  Building wheel for et-xmlfile (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for et-xmlfile: filename=et_xmlfile-1.0.1-py3-none-any.whl size=8913 sha256=ce5a99a41fa37f64958bdc1f6b6182974ec491e5dc8e5f19f741f79f20f68d22\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/e2/bd/55/048b4fd505716c4c298f42ee02dffd9496bb6d212b266c7f31\r\n",
      "Successfully built et-xmlfile\r\n",
      "Installing collected packages: et-xmlfile, openpyxl\r\n",
      "Successfully installed et-xmlfile-1.0.1 openpyxl-3.0.7\r\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "#Author: Raquel Ricoy\n",
    "\n",
    "#Benchmark to study Kaggle's GPUs, CPUs and TPUs potential.\n",
    "#It's going to use Pytorch and to stablish a script to calculate its performance and GFLOPS.\n",
    "\n",
    "#Install pytorch\n",
    "#!conda install -y pytorch torchvision -c pytorch\n",
    "\n",
    "#Install openpyxl to import an excel with the operations in pandas\n",
    "!pip install openpyxl\n",
    "\n",
    "import torch\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "import os\n",
    "#print(os.listdir(\"../input\"))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n",
    "\n",
    "#Importing Libraries needed for use torch\n",
    "import timeit\n",
    "import torch.utils.benchmark as benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "considerable-allowance",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-23T16:54:41.283977Z",
     "iopub.status.busy": "2021-04-23T16:54:41.283332Z",
     "iopub.status.idle": "2021-04-23T16:54:41.287285Z",
     "shell.execute_reply": "2021-04-23T16:54:41.286879Z"
    },
    "papermill": {
     "duration": 0.019342,
     "end_time": "2021-04-23T16:54:41.287402",
     "exception": false,
     "start_time": "2021-04-23T16:54:41.268060",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Functions obtained from Torch Webpages by PyTorch Benchmarks\n",
    "def batched_dot_mul_sum(a, b):\n",
    "    '''Computes batched dot by multiplying and summing'''\n",
    "    return a.mul(b).sum(-1)\n",
    "\n",
    "def batched_dot_bmm(a, b):\n",
    "    '''Computes batched dot by reducing to bmm'''\n",
    "    a = a.reshape(-1, 1, a.shape[-1])\n",
    "    b = b.reshape(-1, b.shape[-1], 1)\n",
    "    return torch.bmm(a, b).flatten(-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fatal-flight",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-23T16:54:41.315335Z",
     "iopub.status.busy": "2021-04-23T16:54:41.313620Z",
     "iopub.status.idle": "2021-04-23T16:54:41.315990Z",
     "shell.execute_reply": "2021-04-23T16:54:41.316397Z"
    },
    "papermill": {
     "duration": 0.01951,
     "end_time": "2021-04-23T16:54:41.316537",
     "exception": false,
     "start_time": "2021-04-23T16:54:41.297027",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Method that do the benchmark and compare results with dot mul sum implementations and vectorSum\n",
    "#Anotation: We cannot change the block threads in pytorch for GPU, it's always 256 threads per block! So the 1 threads that put in benchmark is erroneus and put it by default\n",
    "def benchMark(sizes):\n",
    "    results = []\n",
    "    if(len(sizes) == 0):\n",
    "        print(\"Parameter 'sizes' has to a have minumun of 1 parameters\")\n",
    "        return\n",
    "    \n",
    "    for n in sizes:\n",
    "        # label and sub_label are the rows\n",
    "        # description is the column\n",
    "        label = 'Batched dot'\n",
    "        sub_label = f'[{n}, {n}]'\n",
    "        xCPU = torch.ones(n, n)\n",
    "        xCUDA = xCPU.to(device=\"cuda:0\")\n",
    "        results.append(benchmark.Timer(\n",
    "                stmt='batched_dot_mul_sum(x, x)',\n",
    "                setup='from __main__ import batched_dot_mul_sum',\n",
    "                globals={'x': xCUDA},\n",
    "                label=label,\n",
    "                sub_label=sub_label,\n",
    "                description='mul/sum',\n",
    "            ).blocked_autorange(min_run_time=1))\n",
    "        results.append(benchmark.Timer(\n",
    "                stmt='batched_dot_bmm(x, x)',\n",
    "                setup='from __main__ import batched_dot_bmm',\n",
    "                globals={'x': xCUDA},\n",
    "                label=label,\n",
    "                sub_label=sub_label,\n",
    "                description='bmm',\n",
    "            ).blocked_autorange(min_run_time=1))\n",
    "    compare = benchmark.Compare(results)\n",
    "    compare.print()\n",
    "    return compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "lyric-worker",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-23T16:54:41.345324Z",
     "iopub.status.busy": "2021-04-23T16:54:41.344624Z",
     "iopub.status.idle": "2021-04-23T16:54:41.349424Z",
     "shell.execute_reply": "2021-04-23T16:54:41.348571Z"
    },
    "papermill": {
     "duration": 0.023083,
     "end_time": "2021-04-23T16:54:41.349583",
     "exception": false,
     "start_time": "2021-04-23T16:54:41.326500",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available\n",
      "GPU device where we are gonna execute tests:  Tesla P100-PCIE-16GB\n"
     ]
    }
   ],
   "source": [
    "#Evaluating with which GPU we are going to use\n",
    "if torch.cuda.is_available(): \n",
    "    print(\"GPU is available\")\n",
    "    print(\"GPU device where we are gonna execute tests: \",torch.cuda.get_device_name())\n",
    "else:\n",
    "    print(\"GPU is NOT available\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "deluxe-sphere",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-23T16:54:41.376995Z",
     "iopub.status.busy": "2021-04-23T16:54:41.376482Z",
     "iopub.status.idle": "2021-04-23T16:56:47.508277Z",
     "shell.execute_reply": "2021-04-23T16:56:47.509261Z"
    },
    "papermill": {
     "duration": 126.148971,
     "end_time": "2021-04-23T16:56:47.509503",
     "exception": false,
     "start_time": "2021-04-23T16:54:41.360532",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benchmark execution:  1 \n",
      "\n",
      "[-------------- Batched dot ---------------]\n",
      "                      |  mul/sum  |    bmm  \n",
      "1 threads: ---------------------------------\n",
      "      [512, 512]      |     20.1  |     33.3\n",
      "      [1024, 1024]    |     27.7  |     20.1\n",
      "      [2048, 2048]    |     99.7  |     72.2\n",
      "      [4096, 4096]    |    376.9  |    268.0\n",
      "      [8192, 8192]    |   1454.8  |    995.5\n",
      "      [16384, 16384]  |   5754.0  |   3851.0\n",
      "      [32768, 32768]  |  22985.8  |  15214.9\n",
      "\n",
      "Times are in microseconds (us).\n",
      "\n",
      "Benchmark execution:  2 \n",
      "\n",
      "[-------------- Batched dot ---------------]\n",
      "                      |  mul/sum  |    bmm  \n",
      "1 threads: ---------------------------------\n",
      "      [512, 512]      |     20.4  |     20.8\n",
      "      [1024, 1024]    |     27.6  |     20.2\n",
      "      [2048, 2048]    |     99.6  |     72.0\n",
      "      [4096, 4096]    |    377.0  |    267.9\n",
      "      [8192, 8192]    |   1454.8  |    995.4\n",
      "      [16384, 16384]  |   5753.7  |   3850.5\n",
      "      [32768, 32768]  |  22987.4  |  15215.1\n",
      "\n",
      "Times are in microseconds (us).\n",
      "\n",
      "Benchmark execution:  3 \n",
      "\n",
      "[-------------- Batched dot ---------------]\n",
      "                      |  mul/sum  |    bmm  \n",
      "1 threads: ---------------------------------\n",
      "      [512, 512]      |     20.1  |     20.0\n",
      "      [1024, 1024]    |     27.6  |     20.1\n",
      "      [2048, 2048]    |     99.7  |     72.0\n",
      "      [4096, 4096]    |    377.0  |    267.9\n",
      "      [8192, 8192]    |   1454.5  |    995.6\n",
      "      [16384, 16384]  |   5753.9  |   3850.6\n",
      "      [32768, 32768]  |  22987.3  |  15217.4\n",
      "\n",
      "Times are in microseconds (us).\n",
      "\n",
      "Benchmark execution:  4 \n",
      "\n",
      "[-------------- Batched dot ---------------]\n",
      "                      |  mul/sum  |    bmm  \n",
      "1 threads: ---------------------------------\n",
      "      [512, 512]      |     20.1  |     19.9\n",
      "      [1024, 1024]    |     27.8  |     20.1\n",
      "      [2048, 2048]    |     99.6  |     72.0\n",
      "      [4096, 4096]    |    377.2  |    268.0\n",
      "      [8192, 8192]    |   1454.4  |    995.5\n",
      "      [16384, 16384]  |   5753.8  |   3851.3\n",
      "      [32768, 32768]  |  22986.5  |  15216.1\n",
      "\n",
      "Times are in microseconds (us).\n",
      "\n",
      "Benchmark execution:  5 \n",
      "\n",
      "[-------------- Batched dot ---------------]\n",
      "                      |  mul/sum  |    bmm  \n",
      "1 threads: ---------------------------------\n",
      "      [512, 512]      |     20.2  |     19.9\n",
      "      [1024, 1024]    |     27.6  |     20.2\n",
      "      [2048, 2048]    |     99.6  |     72.0\n",
      "      [4096, 4096]    |    377.1  |    267.9\n",
      "      [8192, 8192]    |   1454.7  |    995.6\n",
      "      [16384, 16384]  |   5753.9  |   3850.7\n",
      "      [32768, 32768]  |  22986.3  |  15220.9\n",
      "\n",
      "Times are in microseconds (us).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#The limit dimension of the sizes is [65536,65536]. It is running out of memory with that sizes\n",
    "sizes = [512,1024,2048,4096,8192,16384,32768]\n",
    "compares = []\n",
    "\n",
    "#The benchmark execute 5 times to gather data and afterwards \n",
    "for i in range(0,5):\n",
    "    print(\"Benchmark execution: \",i+1, \"\\n\")\n",
    "    compares.insert(i,benchMark(sizes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "judicial-constant",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-23T16:56:47.558746Z",
     "iopub.status.busy": "2021-04-23T16:56:47.558001Z",
     "iopub.status.idle": "2021-04-23T16:56:47.562051Z",
     "shell.execute_reply": "2021-04-23T16:56:47.563307Z"
    },
    "papermill": {
     "duration": 0.03377,
     "end_time": "2021-04-23T16:56:47.563504",
     "exception": false,
     "start_time": "2021-04-23T16:56:47.529734",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def ownBenchmark(sizes,writerCSV,operation):\n",
    "    cuda0 = torch.device(\"cuda:0\")\n",
    "    for i in range(0,5):\n",
    "        print(\"\\nBenchmark execution for \",operation,\": \",i+1, \"\\n\")\n",
    "        for n in sizes:\n",
    "            timeInit = time.time()\n",
    "            xCPU = torch.ones(n, n)\n",
    "            xCUDA = xCPU.to(device=cuda0)\n",
    "            if(operation == \"mul_sum\"):\n",
    "                batched_dot_mul_sum(xCUDA,xCUDA)\n",
    "            else:\n",
    "                batched_dot_bmm(xCUDA,xCUDA)\n",
    "            torch.cuda.synchronize()\n",
    "            timeFinish = time.time()\n",
    "            print(f\"size matrix [{n}] -> {(timeFinish - timeInit):0.8f} s\")\n",
    "            writer.writerow([operation, n, i+1,(timeFinish - timeInit)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "crazy-lewis",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-23T16:56:47.611846Z",
     "iopub.status.busy": "2021-04-23T16:56:47.611080Z",
     "iopub.status.idle": "2021-04-23T16:57:29.900729Z",
     "shell.execute_reply": "2021-04-23T16:57:29.899998Z"
    },
    "papermill": {
     "duration": 42.317923,
     "end_time": "2021-04-23T16:57:29.900916",
     "exception": false,
     "start_time": "2021-04-23T16:56:47.582993",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Benchmark execution for  mul_sum :  1 \n",
      "\n",
      "size matrix [512] -> 0.00081158 s\n",
      "size matrix [1024] -> 0.00173211 s\n",
      "size matrix [2048] -> 0.00585651 s\n",
      "size matrix [4096] -> 0.05053329 s\n",
      "size matrix [8192] -> 0.19195271 s\n",
      "size matrix [16384] -> 0.75844502 s\n",
      "size matrix [32768] -> 3.02184081 s\n",
      "\n",
      "Benchmark execution for  mul_sum :  2 \n",
      "\n",
      "size matrix [512] -> 0.13119888 s\n",
      "size matrix [1024] -> 0.00174379 s\n",
      "size matrix [2048] -> 0.00585246 s\n",
      "size matrix [4096] -> 0.04701233 s\n",
      "size matrix [8192] -> 0.19895434 s\n",
      "size matrix [16384] -> 0.75621796 s\n",
      "size matrix [32768] -> 3.00305867 s\n",
      "\n",
      "Benchmark execution for  mul_sum :  3 \n",
      "\n",
      "size matrix [512] -> 0.13361478 s\n",
      "size matrix [1024] -> 0.00200748 s\n",
      "size matrix [2048] -> 0.00574160 s\n",
      "size matrix [4096] -> 0.04801488 s\n",
      "size matrix [8192] -> 0.19183421 s\n",
      "size matrix [16384] -> 0.75955653 s\n",
      "size matrix [32768] -> 3.15847158 s\n",
      "\n",
      "Benchmark execution for  mul_sum :  4 \n",
      "\n",
      "size matrix [512] -> 0.13224888 s\n",
      "size matrix [1024] -> 0.00176024 s\n",
      "size matrix [2048] -> 0.00581551 s\n",
      "size matrix [4096] -> 0.04694939 s\n",
      "size matrix [8192] -> 0.19163561 s\n",
      "size matrix [16384] -> 0.75802755 s\n",
      "size matrix [32768] -> 3.03417230 s\n",
      "\n",
      "Benchmark execution for  mul_sum :  5 \n",
      "\n",
      "size matrix [512] -> 0.13216209 s\n",
      "size matrix [1024] -> 0.00173616 s\n",
      "size matrix [2048] -> 0.00573063 s\n",
      "size matrix [4096] -> 0.04645443 s\n",
      "size matrix [8192] -> 0.18970442 s\n",
      "size matrix [16384] -> 0.75613499 s\n",
      "size matrix [32768] -> 3.09249139 s\n",
      "\n",
      "Benchmark execution for  bmm :  1 \n",
      "\n",
      "size matrix [512] -> 0.00084662 s\n",
      "size matrix [1024] -> 0.00188518 s\n",
      "size matrix [2048] -> 0.00588369 s\n",
      "size matrix [4096] -> 0.04911160 s\n",
      "size matrix [8192] -> 0.18917203 s\n",
      "size matrix [16384] -> 0.75468898 s\n",
      "size matrix [32768] -> 3.01409936 s\n",
      "\n",
      "Benchmark execution for  bmm :  2 \n",
      "\n",
      "size matrix [512] -> 0.13148308 s\n",
      "size matrix [1024] -> 0.00170898 s\n",
      "size matrix [2048] -> 0.00582886 s\n",
      "size matrix [4096] -> 0.04704666 s\n",
      "size matrix [8192] -> 0.19133878 s\n",
      "size matrix [16384] -> 0.75656891 s\n",
      "size matrix [32768] -> 3.00170040 s\n",
      "\n",
      "Benchmark execution for  bmm :  3 \n",
      "\n",
      "size matrix [512] -> 0.13182712 s\n",
      "size matrix [1024] -> 0.00174642 s\n",
      "size matrix [2048] -> 0.00583053 s\n",
      "size matrix [4096] -> 0.04698825 s\n",
      "size matrix [8192] -> 0.19112611 s\n",
      "size matrix [16384] -> 0.75628996 s\n",
      "size matrix [32768] -> 3.50457883 s\n",
      "\n",
      "Benchmark execution for  bmm :  4 \n",
      "\n",
      "size matrix [512] -> 0.13220334 s\n",
      "size matrix [1024] -> 0.00170302 s\n",
      "size matrix [2048] -> 0.00573516 s\n",
      "size matrix [4096] -> 0.04665422 s\n",
      "size matrix [8192] -> 0.18925834 s\n",
      "size matrix [16384] -> 0.76354551 s\n",
      "size matrix [32768] -> 3.01372862 s\n",
      "\n",
      "Benchmark execution for  bmm :  5 \n",
      "\n",
      "size matrix [512] -> 0.13220954 s\n",
      "size matrix [1024] -> 0.00175047 s\n",
      "size matrix [2048] -> 0.00580645 s\n",
      "size matrix [4096] -> 0.04708815 s\n",
      "size matrix [8192] -> 0.19206715 s\n",
      "size matrix [16384] -> 0.75500512 s\n",
      "size matrix [32768] -> 3.01498795 s\n"
     ]
    }
   ],
   "source": [
    "#Now my own benchmark. With this i going to measure Speed ups and efficiencies. The pytorch benchmark give us too good results to be true...\n",
    "# We are going to use the library time from python and do the syncronizations to the gpu device\n",
    "import time #-> time.time() returns the time in seconds\n",
    "import csv #We are going to generate an csv with the results to work with pandas\n",
    "\n",
    "sizes = [512,1024,2048,4096,8192,16384,32768] # maximun size withou running out memory -> 65536\n",
    "\n",
    "with open('results_gpu.csv', 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"operation\", \"sizeMatrix\", \"numberCase\",\"timeElpased\"])\n",
    "    ownBenchmark(sizes,writer,\"mul_sum\")\n",
    "    ownBenchmark(sizes,writer,\"bmm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "modified-somerset",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-23T16:57:29.961227Z",
     "iopub.status.busy": "2021-04-23T16:57:29.949963Z",
     "iopub.status.idle": "2021-04-23T16:57:30.437846Z",
     "shell.execute_reply": "2021-04-23T16:57:30.436842Z"
    },
    "papermill": {
     "duration": 0.516338,
     "end_time": "2021-04-23T16:57:30.438042",
     "exception": false,
     "start_time": "2021-04-23T16:57:29.921704",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 70 entries, 0 to 69\n",
      "Data columns (total 4 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   operation    70 non-null     object \n",
      " 1   sizeMatrix   70 non-null     int64  \n",
      " 2   numberCase   70 non-null     int64  \n",
      " 3   timeElpased  70 non-null     float64\n",
      "dtypes: float64(1), int64(2), object(1)\n",
      "memory usage: 2.3+ KB\n"
     ]
    }
   ],
   "source": [
    "#Generate the excel and giving a little of format\n",
    "#TODO include the calculate of FLOPS in excel/dataFrame\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"results_gpu.csv\")\n",
    "df.info()\n",
    "\n",
    "df_sorted = df.sort_values(by=[\"operation\",\"numberCase\"])\n",
    "\n",
    "df_sorted.to_excel(\"results_gpu_excel.xlsx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 187.638072,
   "end_time": "2021-04-23T16:57:31.883789",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-04-23T16:54:24.245717",
   "version": "2.3.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
