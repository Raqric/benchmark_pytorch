{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "adverse-counter",
   "metadata": {
    "papermill": {
     "duration": 0.007364,
     "end_time": "2021-04-22T14:45:13.615231",
     "exception": false,
     "start_time": "2021-04-22T14:45:13.607867",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    "# Benchmarking GPUs in Kaggle\n",
    "\n",
    "In this Kaggle notebook there is an adaptation from my Benchmark CPU to GPU using pytorch benchmark. The main method (benchmark) it change the input parameters, now it just needs the sizes to process. We are going to check the results and analyse them. Besides, there's my own method for timing, and it'is going to be used to analyse the timeit library from pytorch. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rental-future",
   "metadata": {
    "papermill": {
     "duration": 0.005961,
     "end_time": "2021-04-22T14:45:13.627531",
     "exception": false,
     "start_time": "2021-04-22T14:45:13.621570",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## My CPU Benchmark adapted to GPU\n",
    "\n",
    "Pytorch has hard coded a block size of 256 threads. So there's only one execution per matrix size.\n",
    "\n",
    "One important advertisment! GPU accelerator has to be activated to use this notebook, if not, the notebook is not going to compile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "neither-compiler",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-22T14:45:13.644905Z",
     "iopub.status.busy": "2021-04-22T14:45:13.643476Z",
     "iopub.status.idle": "2021-04-22T14:45:15.479979Z",
     "shell.execute_reply": "2021-04-22T14:45:15.479005Z"
    },
    "papermill": {
     "duration": 1.846466,
     "end_time": "2021-04-22T14:45:15.480140",
     "exception": false,
     "start_time": "2021-04-22T14:45:13.633674",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "#Author: Raquel Ricoy\n",
    "\n",
    "#Benchmark to study Kaggle's GPUs, CPUs and TPUs potential.\n",
    "#It's going to use Pytorch and to stablish a script to calculate its performance and GFLOPS.\n",
    "\n",
    "#Install pytorch\n",
    "#!conda install -y pytorch torchvision -c pytorch\n",
    "\n",
    "import torch\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "import os\n",
    "#print(os.listdir(\"../input\"))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n",
    "\n",
    "#Importing Libraries needed for use torch\n",
    "import timeit\n",
    "import torch.utils.benchmark as benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "welsh-password",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-22T14:45:15.499010Z",
     "iopub.status.busy": "2021-04-22T14:45:15.498329Z",
     "iopub.status.idle": "2021-04-22T14:45:15.500652Z",
     "shell.execute_reply": "2021-04-22T14:45:15.501145Z"
    },
    "papermill": {
     "duration": 0.014357,
     "end_time": "2021-04-22T14:45:15.501265",
     "exception": false,
     "start_time": "2021-04-22T14:45:15.486908",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Functions obtained from Torch Webpages by PyTorch Benchmarks\n",
    "def batched_dot_mul_sum(a, b):\n",
    "    '''Computes batched dot by multiplying and summing'''\n",
    "    return a.mul(b).sum(-1)\n",
    "\n",
    "def batched_dot_bmm(a, b):\n",
    "    '''Computes batched dot by reducing to bmm'''\n",
    "    a = a.reshape(-1, 1, a.shape[-1])\n",
    "    b = b.reshape(-1, b.shape[-1], 1)\n",
    "    return torch.bmm(a, b).flatten(-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "multiple-applicant",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-22T14:45:15.521253Z",
     "iopub.status.busy": "2021-04-22T14:45:15.520604Z",
     "iopub.status.idle": "2021-04-22T14:45:15.523511Z",
     "shell.execute_reply": "2021-04-22T14:45:15.523095Z"
    },
    "papermill": {
     "duration": 0.015921,
     "end_time": "2021-04-22T14:45:15.523613",
     "exception": false,
     "start_time": "2021-04-22T14:45:15.507692",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Method that do the benchmark and compare results with dot mul sum implementations and vectorSum\n",
    "#Anotation: We cannot change the block threads in pytorch for GPU, it's always 256 threads per block! So the 1 threads that put in benchmark is erroneus and put it by default\n",
    "def benchMark(sizes):\n",
    "    results = []\n",
    "    if(len(sizes) == 0):\n",
    "        print(\"Parameter 'sizes' has to a have minumun of 1 parameters\")\n",
    "        return\n",
    "    \n",
    "    for n in sizes:\n",
    "        # label and sub_label are the rows\n",
    "        # description is the column\n",
    "        label = 'Batched dot'\n",
    "        sub_label = f'[{n}, {n}]'\n",
    "        xCPU = torch.ones(n, n)\n",
    "        xCUDA = xCPU.to(device=\"cuda:0\")\n",
    "        results.append(benchmark.Timer(\n",
    "                stmt='batched_dot_mul_sum(x, x)',\n",
    "                setup='from __main__ import batched_dot_mul_sum',\n",
    "                globals={'x': xCUDA},\n",
    "                label=label,\n",
    "                sub_label=sub_label,\n",
    "                description='mul/sum',\n",
    "            ).blocked_autorange(min_run_time=1))\n",
    "        results.append(benchmark.Timer(\n",
    "                stmt='batched_dot_bmm(x, x)',\n",
    "                setup='from __main__ import batched_dot_bmm',\n",
    "                globals={'x': xCUDA},\n",
    "                label=label,\n",
    "                sub_label=sub_label,\n",
    "                description='bmm',\n",
    "            ).blocked_autorange(min_run_time=1))\n",
    "    compare = benchmark.Compare(results)\n",
    "    compare.print()\n",
    "    return compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aquatic-ballot",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-22T14:45:15.544629Z",
     "iopub.status.busy": "2021-04-22T14:45:15.543795Z",
     "iopub.status.idle": "2021-04-22T14:45:15.547541Z",
     "shell.execute_reply": "2021-04-22T14:45:15.547987Z"
    },
    "papermill": {
     "duration": 0.018079,
     "end_time": "2021-04-22T14:45:15.548103",
     "exception": false,
     "start_time": "2021-04-22T14:45:15.530024",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available\n",
      "GPU device where we are gonna execute tests:  Tesla P100-PCIE-16GB\n"
     ]
    }
   ],
   "source": [
    "#Evaluating with which GPU we are going to use\n",
    "if torch.cuda.is_available(): \n",
    "    print(\"GPU is available\")\n",
    "    print(\"GPU device where we are gonna execute tests: \",torch.cuda.get_device_name())\n",
    "else:\n",
    "    print(\"GPU is NOT available\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "wicked-geology",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-22T14:45:15.567578Z",
     "iopub.status.busy": "2021-04-22T14:45:15.566969Z",
     "iopub.status.idle": "2021-04-22T14:47:28.494695Z",
     "shell.execute_reply": "2021-04-22T14:47:28.495275Z"
    },
    "papermill": {
     "duration": 132.940308,
     "end_time": "2021-04-22T14:47:28.495499",
     "exception": false,
     "start_time": "2021-04-22T14:45:15.555191",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benchmark execution:  1 \n",
      "\n",
      "[-------------- Batched dot ---------------]\n",
      "                      |  mul/sum  |    bmm  \n",
      "1 threads: ---------------------------------\n",
      "      [512, 512]      |     19.1  |     33.1\n",
      "      [1024, 1024]    |     27.6  |     19.9\n",
      "      [2048, 2048]    |     99.5  |     71.9\n",
      "      [4096, 4096]    |    379.9  |    267.7\n",
      "      [8192, 8192]    |   1454.5  |    993.5\n",
      "      [16384, 16384]  |   5753.3  |   3851.8\n",
      "      [32768, 32768]  |  22984.6  |  15215.4\n",
      "\n",
      "Times are in microseconds (us).\n",
      "\n",
      "Benchmark execution:  2 \n",
      "\n",
      "[-------------- Batched dot ---------------]\n",
      "                      |  mul/sum  |    bmm  \n",
      "1 threads: ---------------------------------\n",
      "      [512, 512]      |     19.2  |     19.8\n",
      "      [1024, 1024]    |     27.7  |     20.0\n",
      "      [2048, 2048]    |     99.5  |     72.1\n",
      "      [4096, 4096]    |    380.1  |    267.8\n",
      "      [8192, 8192]    |   1454.8  |    994.0\n",
      "      [16384, 16384]  |   5754.0  |   3852.5\n",
      "      [32768, 32768]  |  22986.4  |  15218.7\n",
      "\n",
      "Times are in microseconds (us).\n",
      "\n",
      "Benchmark execution:  3 \n",
      "\n",
      "[-------------- Batched dot ---------------]\n",
      "                      |  mul/sum  |    bmm  \n",
      "1 threads: ---------------------------------\n",
      "      [512, 512]      |     19.8  |     20.1\n",
      "      [1024, 1024]    |     27.7  |     20.1\n",
      "      [2048, 2048]    |     99.6  |     72.1\n",
      "      [4096, 4096]    |    380.0  |    267.8\n",
      "      [8192, 8192]    |   1454.7  |    993.1\n",
      "      [16384, 16384]  |   5753.5  |   3852.2\n",
      "      [32768, 32768]  |  22986.7  |  15220.2\n",
      "\n",
      "Times are in microseconds (us).\n",
      "\n",
      "Benchmark execution:  4 \n",
      "\n",
      "[-------------- Batched dot ---------------]\n",
      "                      |  mul/sum  |    bmm  \n",
      "1 threads: ---------------------------------\n",
      "      [512, 512]      |     19.9  |     29.9\n",
      "      [1024, 1024]    |     27.8  |     20.0\n",
      "      [2048, 2048]    |     99.6  |     72.1\n",
      "      [4096, 4096]    |    380.2  |    267.8\n",
      "      [8192, 8192]    |   1454.7  |    994.0\n",
      "      [16384, 16384]  |   5753.9  |   3852.4\n",
      "      [32768, 32768]  |  22986.3  |  15219.7\n",
      "\n",
      "Times are in microseconds (us).\n",
      "\n",
      "Benchmark execution:  5 \n",
      "\n",
      "[-------------- Batched dot ---------------]\n",
      "                      |  mul/sum  |    bmm  \n",
      "1 threads: ---------------------------------\n",
      "      [512, 512]      |     19.3  |     21.3\n",
      "      [1024, 1024]    |     27.7  |     20.0\n",
      "      [2048, 2048]    |     99.6  |     72.1\n",
      "      [4096, 4096]    |    380.1  |    267.8\n",
      "      [8192, 8192]    |   1454.8  |    993.0\n",
      "      [16384, 16384]  |   5753.8  |   3852.2\n",
      "      [32768, 32768]  |  22986.4  |  15219.8\n",
      "\n",
      "Times are in microseconds (us).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#The limit dimension of the sizes is [65536,65536]. It is running out of memory with that sizes\n",
    "sizes = [512,1024,2048,4096,8192,16384,32768]\n",
    "compares = []\n",
    "\n",
    "#The benchmark execute 5 times to gather data and afterwards \n",
    "for i in range(0,5):\n",
    "    print(\"Benchmark execution: \",i+1, \"\\n\")\n",
    "    compares.insert(i,benchMark(sizes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bacterial-aluminum",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-22T14:47:28.522793Z",
     "iopub.status.busy": "2021-04-22T14:47:28.521890Z",
     "iopub.status.idle": "2021-04-22T14:47:49.731051Z",
     "shell.execute_reply": "2021-04-22T14:47:49.730141Z"
    },
    "papermill": {
     "duration": 21.226111,
     "end_time": "2021-04-22T14:47:49.731205",
     "exception": false,
     "start_time": "2021-04-22T14:47:28.505094",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Benchmark execution for batched_dot_mul_sum:  1 \n",
      "\n",
      "size matrix [512] -> 0.00163770 s\n",
      "size matrix [1024] -> 0.00173306 s\n",
      "size matrix [2048] -> 0.00610614 s\n",
      "size matrix [4096] -> 0.04885530 s\n",
      "size matrix [8192] -> 0.19165254 s\n",
      "size matrix [16384] -> 0.75894785 s\n",
      "size matrix [32768] -> 3.18522787 s\n",
      "\n",
      "Benchmark execution for batched_dot_mul_sum:  2 \n",
      "\n",
      "size matrix [512] -> 0.13693380 s\n",
      "size matrix [1024] -> 0.00176907 s\n",
      "size matrix [2048] -> 0.00612235 s\n",
      "size matrix [4096] -> 0.04758263 s\n",
      "size matrix [8192] -> 0.19416809 s\n",
      "size matrix [16384] -> 0.76451230 s\n",
      "size matrix [32768] -> 3.05518007 s\n",
      "\n",
      "Benchmark execution for batched_dot_mul_sum:  3 \n",
      "\n",
      "size matrix [512] -> 0.13375497 s\n",
      "size matrix [1024] -> 0.00179148 s\n",
      "size matrix [2048] -> 0.00639558 s\n",
      "size matrix [4096] -> 0.04699349 s\n",
      "size matrix [8192] -> 0.19169211 s\n",
      "size matrix [16384] -> 0.76087332 s\n",
      "size matrix [32768] -> 3.03962612 s\n",
      "\n",
      "Benchmark execution for batched_dot_mul_sum:  4 \n",
      "\n",
      "size matrix [512] -> 0.13376665 s\n",
      "size matrix [1024] -> 0.00176144 s\n",
      "size matrix [2048] -> 0.00603724 s\n",
      "size matrix [4096] -> 0.04730988 s\n",
      "size matrix [8192] -> 0.21077037 s\n",
      "size matrix [16384] -> 0.86409497 s\n",
      "size matrix [32768] -> 3.02242875 s\n",
      "\n",
      "Benchmark execution for batched_dot_mul_sum:  5 \n",
      "\n",
      "size matrix [512] -> 0.13226247 s\n",
      "size matrix [1024] -> 0.00169206 s\n",
      "size matrix [2048] -> 0.00591326 s\n",
      "size matrix [4096] -> 0.04675579 s\n",
      "size matrix [8192] -> 0.19051147 s\n",
      "size matrix [16384] -> 0.76016712 s\n",
      "size matrix [32768] -> 3.19483709 s\n"
     ]
    }
   ],
   "source": [
    "#OWN METHODs\n",
    "# We are going to use the library time from python and do the syncronizations to the gpu device\n",
    "import time #-> time.time() returns the time in seconds\n",
    "\n",
    "cuda0 = torch.device(\"cuda:0\")\n",
    "\n",
    "sizes = [512,1024,2048,4096,8192,16384,32768] # maximun size withou running out memory -> 65536\n",
    "\n",
    "#Firstly batched_dot_mul_sum\n",
    "for i in range(0,5):\n",
    "    print(\"\\nBenchmark execution for batched_dot_mul_sum: \",i+1, \"\\n\")\n",
    "    for n in sizes:\n",
    "        timeInit = time.time()\n",
    "\n",
    "        xCPU = torch.ones(n, n)\n",
    "        xCUDA = xCPU.to(device=cuda0)\n",
    "\n",
    "        timeInitMulSum = time.time()\n",
    "        batched_dot_mul_sum(xCUDA,xCUDA)\n",
    "        torch.cuda.synchronize()\n",
    "        timeFinishMulSum = time.time()\n",
    "\n",
    "        timeFinish = time.time()\n",
    "\n",
    "        print(f\"size matrix [{n}] -> {(timeFinish - timeInit):0.8f} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "major-trust",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-22T14:47:49.896050Z",
     "iopub.status.busy": "2021-04-22T14:47:49.762382Z",
     "iopub.status.idle": "2021-04-22T14:48:10.841809Z",
     "shell.execute_reply": "2021-04-22T14:48:10.842383Z"
    },
    "papermill": {
     "duration": 21.09811,
     "end_time": "2021-04-22T14:48:10.842584",
     "exception": false,
     "start_time": "2021-04-22T14:47:49.744474",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Benchmark execution for batched_dot_bmm:  1 \n",
      "\n",
      "size matrix [512] -> 0.13341093 s\n",
      "size matrix [1024] -> 0.00225258 s\n",
      "size matrix [2048] -> 0.00596809 s\n",
      "size matrix [4096] -> 0.04708171 s\n",
      "size matrix [8192] -> 0.19160604 s\n",
      "size matrix [16384] -> 0.75696254 s\n",
      "size matrix [32768] -> 3.18731189 s\n",
      "\n",
      "Benchmark execution for batched_dot_bmm:  2 \n",
      "\n",
      "size matrix [512] -> 0.13329959 s\n",
      "size matrix [1024] -> 0.00174069 s\n",
      "size matrix [2048] -> 0.00616002 s\n",
      "size matrix [4096] -> 0.04675460 s\n",
      "size matrix [8192] -> 0.18924212 s\n",
      "size matrix [16384] -> 0.75205564 s\n",
      "size matrix [32768] -> 3.01112890 s\n",
      "\n",
      "Benchmark execution for batched_dot_bmm:  3 \n",
      "\n",
      "size matrix [512] -> 0.14559960 s\n",
      "size matrix [1024] -> 0.00174379 s\n",
      "size matrix [2048] -> 0.00632596 s\n",
      "size matrix [4096] -> 0.05021501 s\n",
      "size matrix [8192] -> 0.19839668 s\n",
      "size matrix [16384] -> 0.75647831 s\n",
      "size matrix [32768] -> 3.02638221 s\n",
      "\n",
      "Benchmark execution for batched_dot_bmm:  4 \n",
      "\n",
      "size matrix [512] -> 0.13623810 s\n",
      "size matrix [1024] -> 0.00173807 s\n",
      "size matrix [2048] -> 0.00605655 s\n",
      "size matrix [4096] -> 0.04720020 s\n",
      "size matrix [8192] -> 0.19117951 s\n",
      "size matrix [16384] -> 0.77852488 s\n",
      "size matrix [32768] -> 3.12067437 s\n",
      "\n",
      "Benchmark execution for batched_dot_bmm:  5 \n",
      "\n",
      "size matrix [512] -> 0.13235831 s\n",
      "size matrix [1024] -> 0.00168991 s\n",
      "size matrix [2048] -> 0.00597072 s\n",
      "size matrix [4096] -> 0.04667068 s\n",
      "size matrix [8192] -> 0.19038343 s\n",
      "size matrix [16384] -> 0.75294447 s\n",
      "size matrix [32768] -> 3.00869679 s\n"
     ]
    }
   ],
   "source": [
    "#Now batched_dot_bmm\n",
    "for i in range(0,5):\n",
    "    print(\"\\nBenchmark execution for batched_dot_bmm: \",i+1, \"\\n\")\n",
    "    for n in sizes:\n",
    "        timeInit = time.time()\n",
    "\n",
    "        xCPU = torch.ones(n, n)\n",
    "        xCUDA = xCPU.to(device=cuda0)\n",
    "        batched_dot_bmm(xCUDA,xCUDA)\n",
    "        torch.cuda.synchronize()\n",
    "        \n",
    "        timeFinish = time.time()\n",
    "\n",
    "        print(f\"size matrix [{n}] -> {(timeFinish - timeInit):0.8f} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "sweet-saint",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-22T14:48:10.882161Z",
     "iopub.status.busy": "2021-04-22T14:48:10.881509Z",
     "iopub.status.idle": "2021-04-22T14:48:10.884443Z",
     "shell.execute_reply": "2021-04-22T14:48:10.884027Z"
    },
    "papermill": {
     "duration": 0.023458,
     "end_time": "2021-04-22T14:48:10.884548",
     "exception": false,
     "start_time": "2021-04-22T14:48:10.861090",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#To generate an out_file, not necessary to use\n",
    "#Generate a file.out with the results.\n",
    "#Benchmark from pytorch just generate a print from the sdtout, so we need to change the stdout to write it in a file.\n",
    "#import sys\n",
    "\n",
    "#original_stdout = sys.stdout # Save a reference to the original standard output\n",
    "\n",
    "#with open('output_gpu_benchmark.out', 'w') as file:\n",
    "#    sys.stdout = file # Change the standard output to the file we created.\n",
    "#    i=1\n",
    "#    for compare in compares:\n",
    "#        print(\"Benchmark execution: \",i, \"\\n\")\n",
    "#        compare.print()\n",
    "#        i += 1\n",
    "#    sys.stdout = original_stdout # Reset the standard output to its original value"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 184.733781,
   "end_time": "2021-04-22T14:48:13.406269",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-04-22T14:45:08.672488",
   "version": "2.3.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
