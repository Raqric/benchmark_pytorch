{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "opposite-sport",
   "metadata": {
    "papermill": {
     "duration": 0.007717,
     "end_time": "2021-04-15T15:48:47.287497",
     "exception": false,
     "start_time": "2021-04-15T15:48:47.279780",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Benchmark for TPU using pytorch\n",
    "\n",
    "This code is going to do some computational test about the performance that a TPU can obtain. It's an adaptation from my previuous benchmark using pytorch. However, the script to use pytorch-xla (the module that uses the TPU) it's only available to use with pytorch 1.6, it's not available to use it with current version (1.7), so, the BenchMark module from pytorch it's not included and it has to be replaced it by using the timeit module.\n",
    "\n",
    "Using timeit module made that executions can have a warmp up delay of a 2 us approximately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bottom-flower",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-15T15:48:47.310155Z",
     "iopub.status.busy": "2021-04-15T15:48:47.309420Z",
     "iopub.status.idle": "2021-04-15T15:50:01.521685Z",
     "shell.execute_reply": "2021-04-15T15:50:01.520869Z"
    },
    "papermill": {
     "duration": 74.226774,
     "end_time": "2021-04-15T15:50:01.521881",
     "exception": false,
     "start_time": "2021-04-15T15:48:47.295107",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\r\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\r\n",
      "100  5116  100  5116    0     0  51160      0 --:--:-- --:--:-- --:--:-- 51160\r\n",
      "Updating... This may take around 2 minutes.\r\n",
      "Updating TPU runtime to pytorch-dev20200515 ...\r\n",
      "Found existing installation: torch 1.7.0\r\n",
      "Uninstalling torch-1.7.0:\r\n",
      "Done updating TPU runtime\r\n",
      "  Successfully uninstalled torch-1.7.0\r\n",
      "Found existing installation: torchvision 0.8.1\r\n",
      "Uninstalling torchvision-0.8.1:\r\n",
      "  Successfully uninstalled torchvision-0.8.1\r\n",
      "Copying gs://tpu-pytorch/wheels/torch-nightly+20200515-cp37-cp37m-linux_x86_64.whl...\r\n",
      "\r\n",
      "Operation completed over 1 objects/91.0 MiB.                                     \r\n",
      "Copying gs://tpu-pytorch/wheels/torch_xla-nightly+20200515-cp37-cp37m-linux_x86_64.whl...\r\n",
      "\r\n",
      "Operation completed over 1 objects/119.5 MiB.                                    \r\n",
      "Copying gs://tpu-pytorch/wheels/torchvision-nightly+20200515-cp37-cp37m-linux_x86_64.whl...\r\n",
      "\r\n",
      "Operation completed over 1 objects/2.3 MiB.                                      \r\n",
      "Processing ./torch-nightly+20200515-cp37-cp37m-linux_x86_64.whl\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torch==nightly+20200515) (1.19.5)\r\n",
      "Requirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from torch==nightly+20200515) (0.18.2)\r\n",
      "Installing collected packages: torch\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "fastai 2.2.7 requires torchvision<0.9,>=0.8, which is not installed.\r\n",
      "easyocr 1.3.0.1 requires torchvision>=0.5, which is not installed.\r\n",
      "allennlp 2.2.0 requires torchvision<0.10.0,>=0.8.1, which is not installed.\r\n",
      "kornia 0.5.0 requires torch>=1.6.0, but you have torch 1.6.0a0+bf2bbd9 which is incompatible.\r\n",
      "fastai 2.2.7 requires torch<1.8,>=1.7.0, but you have torch 1.6.0a0+bf2bbd9 which is incompatible.\r\n",
      "allennlp 2.2.0 requires torch<1.9.0,>=1.6.0, but you have torch 1.6.0a0+bf2bbd9 which is incompatible.\u001b[0m\r\n",
      "Successfully installed torch-1.6.0a0+bf2bbd9\r\n",
      "Processing ./torch_xla-nightly+20200515-cp37-cp37m-linux_x86_64.whl\r\n",
      "Installing collected packages: torch-xla\r\n",
      "Successfully installed torch-xla-1.6+2b2085a\r\n",
      "Processing ./torchvision-nightly+20200515-cp37-cp37m-linux_x86_64.whl\r\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.7/site-packages (from torchvision==nightly+20200515) (1.6.0a0+bf2bbd9)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torchvision==nightly+20200515) (1.19.5)\r\n",
      "Requirement already satisfied: pillow>=4.1.1 in /opt/conda/lib/python3.7/site-packages (from torchvision==nightly+20200515) (7.2.0)\r\n",
      "Requirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from torch->torchvision==nightly+20200515) (0.18.2)\r\n",
      "Installing collected packages: torchvision\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "fastai 2.2.7 requires torch<1.8,>=1.7.0, but you have torch 1.6.0a0+bf2bbd9 which is incompatible.\r\n",
      "fastai 2.2.7 requires torchvision<0.9,>=0.8, but you have torchvision 0.7.0a0+a6073f0 which is incompatible.\r\n",
      "allennlp 2.2.0 requires torch<1.9.0,>=1.6.0, but you have torch 1.6.0a0+bf2bbd9 which is incompatible.\r\n",
      "allennlp 2.2.0 requires torchvision<0.10.0,>=0.8.1, but you have torchvision 0.7.0a0+a6073f0 which is incompatible.\u001b[0m\r\n",
      "Successfully installed torchvision-0.7.0a0+a6073f0\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "The following NEW packages will be installed:\r\n",
      "  libomp5 libopenblas-dev\r\n",
      "0 upgraded, 2 newly installed, 0 to remove and 23 not upgraded.\r\n",
      "Need to get 4094 kB of archives.\r\n",
      "After this operation, 54.2 MB of additional disk space will be used.\r\n",
      "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libopenblas-dev amd64 0.2.20+ds-4 [3860 kB]\r\n",
      "Get:2 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libomp5 amd64 5.0.1-1 [234 kB]\r\n",
      "Fetched 4094 kB in 1s (3122 kB/s)\r\n",
      "debconf: delaying package configuration, since apt-utils is not installed\r\n",
      "Selecting previously unselected package libopenblas-dev:amd64.\r\n",
      "(Reading database ... 95165 files and directories currently installed.)\r\n",
      "Preparing to unpack .../libopenblas-dev_0.2.20+ds-4_amd64.deb ...\r\n",
      "Unpacking libopenblas-dev:amd64 (0.2.20+ds-4) ...\r\n",
      "Selecting previously unselected package libomp5:amd64.\r\n",
      "Preparing to unpack .../libomp5_5.0.1-1_amd64.deb ...\r\n",
      "Unpacking libomp5:amd64 (5.0.1-1) ...\r\n",
      "Setting up libomp5:amd64 (5.0.1-1) ...\r\n",
      "Setting up libopenblas-dev:amd64 (0.2.20+ds-4) ...\r\n",
      "update-alternatives: using /usr/lib/x86_64-linux-gnu/openblas/libblas.so to provide /usr/lib/x86_64-linux-gnu/libblas.so (libblas.so-x86_64-linux-gnu) in auto mode\r\n",
      "update-alternatives: using /usr/lib/x86_64-linux-gnu/openblas/liblapack.so to provide /usr/lib/x86_64-linux-gnu/liblapack.so (liblapack.so-x86_64-linux-gnu) in auto mode\r\n",
      "Processing triggers for libc-bin (2.27-3ubuntu1.4) ...\r\n"
     ]
    }
   ],
   "source": [
    "!curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\n",
    "!python pytorch-xla-env-setup.py  --apt-packages libomp5 libopenblas-dev # --version=pytorch-1.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "specialized-hawaii",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-15T15:50:01.577480Z",
     "iopub.status.busy": "2021-04-15T15:50:01.576808Z",
     "iopub.status.idle": "2021-04-15T15:50:02.175831Z",
     "shell.execute_reply": "2021-04-15T15:50:02.176746Z"
    },
    "papermill": {
     "duration": 0.629,
     "end_time": "2021-04-15T15:50:02.177061",
     "exception": false,
     "start_time": "2021-04-15T15:50:01.548061",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6.0a0+bf2bbd9\n"
     ]
    }
   ],
   "source": [
    "# imports pytorch\n",
    "import torch\n",
    "\n",
    "print(torch.__version__)\n",
    "\n",
    "# imports the torch_xla package\n",
    "import torch_xla\n",
    "import torch_xla.core.xla_model as xm\n",
    "import platform\n",
    "import os\n",
    "#Importing Libraries needed for use torch\n",
    "import timeit\n",
    "#import torch.utils.benchmark as benchmark #torch_xla it is not compatible with 1.7, where it is the benchmark library\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "composite-owner",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-15T15:50:02.239756Z",
     "iopub.status.busy": "2021-04-15T15:50:02.238901Z",
     "iopub.status.idle": "2021-04-15T15:50:02.242490Z",
     "shell.execute_reply": "2021-04-15T15:50:02.241750Z"
    },
    "papermill": {
     "duration": 0.038046,
     "end_time": "2021-04-15T15:50:02.242641",
     "exception": false,
     "start_time": "2021-04-15T15:50:02.204595",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Functions obtained from Torch Webpages por PyTorch Benchmarks\n",
    "def batched_dot_mul_sum(a, b):\n",
    "    '''Computes batched dot by multiplying and summing'''\n",
    "    return a.mul(b).sum(-1)\n",
    "\n",
    "\n",
    "def batched_dot_bmm(a, b):\n",
    "    '''Computes batched dot by reducing to bmm'''\n",
    "    a = a.reshape(-1, 1, a.shape[-1])\n",
    "    b = b.reshape(-1, b.shape[-1], 1)\n",
    "    return torch.bmm(a, b).flatten(-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "color-qualification",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-15T15:50:02.304330Z",
     "iopub.status.busy": "2021-04-15T15:50:02.303590Z",
     "iopub.status.idle": "2021-04-15T15:50:02.306798Z",
     "shell.execute_reply": "2021-04-15T15:50:02.306246Z"
    },
    "papermill": {
     "duration": 0.037966,
     "end_time": "2021-04-15T15:50:02.306976",
     "exception": false,
     "start_time": "2021-04-15T15:50:02.269010",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def benchMark(sizes,nThreads,dev):   \n",
    "    for n in sizes:\n",
    "        x = torch.ones((n, n),device=dev)\n",
    "        t0 = timeit.Timer(\n",
    "        stmt='batched_dot_mul_sum(x, x)',\n",
    "        setup='from __main__ import batched_dot_mul_sum',\n",
    "        globals={'x': x})\n",
    "\n",
    "        t1 = timeit.Timer(\n",
    "        stmt='batched_dot_bmm(x, x)',\n",
    "        setup='from __main__ import batched_dot_bmm',\n",
    "        globals={'x': x})\n",
    "\n",
    "        print('size of square matrix: ',n)\n",
    "        print(f'mul_sum(x, x):  {t0.timeit(100) / 100 * 1e6:>5.1f} us')\n",
    "        print(f'bmm(x, x):      {t1.timeit(100) / 100 * 1e6:>5.1f} us\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "virgin-atlanta",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-15T15:50:10.428493Z",
     "iopub.status.busy": "2021-04-15T15:50:10.426305Z",
     "iopub.status.idle": "2021-04-15T15:50:14.631491Z",
     "shell.execute_reply": "2021-04-15T15:50:14.632025Z"
    },
    "papermill": {
     "duration": 12.296863,
     "end_time": "2021-04-15T15:50:14.632222",
     "exception": false,
     "start_time": "2021-04-15T15:50:02.335359",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dev = xm.xla_device()\n",
    "\n",
    "sizes = [512,2048,4096,8192,16384,32768,65536,131072,262144]\n",
    "threads = [1] #We put a single thread\n",
    "compares = []\n",
    "\n",
    "#Verifying the correct use of methods from above\n",
    "#Just to verify that works properly in tpu\n",
    "for n in sizes:\n",
    "    x = torch.ones(n, n,device=dev)\n",
    "    #if assert don't show error, it means works properly\n",
    "    assert batched_dot_mul_sum(x, x).allclose(batched_dot_bmm(x, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "weird-assets",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-15T15:50:14.704931Z",
     "iopub.status.busy": "2021-04-15T15:50:14.703795Z",
     "iopub.status.idle": "2021-04-15T15:50:14.864742Z",
     "shell.execute_reply": "2021-04-15T15:50:14.863697Z"
    },
    "papermill": {
     "duration": 0.204751,
     "end_time": "2021-04-15T15:50:14.864987",
     "exception": false,
     "start_time": "2021-04-15T15:50:14.660236",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Generate a file.out with the results.\n",
    "#Benchmark from pytorch just generate a print from the sdtout, so we need to change the stdout to write it in a file.\n",
    "import sys\n",
    "\n",
    "original_stdout = sys.stdout # Save a reference to the original standard output\n",
    "\n",
    "with open('output_benchmark.out', 'w') as file:\n",
    "    sys.stdout = file # Change the standard output to the file we created.\n",
    "    #The benchmark execute 5 times to gather data and afterwards \n",
    "    for i in range(0,5):\n",
    "        print(\"Benchmark execution: \",i+1, \"\\n\")\n",
    "        benchMark(sizes,threads,dev)\n",
    "\n",
    "sys.stdout = original_stdout # Reset the standard output to its original value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "celtic-twenty",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-15T15:50:14.932740Z",
     "iopub.status.busy": "2021-04-15T15:50:14.931661Z",
     "iopub.status.idle": "2021-04-15T15:50:14.964038Z",
     "shell.execute_reply": "2021-04-15T15:50:14.964793Z"
    },
    "papermill": {
     "duration": 0.065985,
     "end_time": "2021-04-15T15:50:14.965086",
     "exception": false,
     "start_time": "2021-04-15T15:50:14.899101",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benchmark execution:  1 \n",
      "\n",
      "\n",
      "\n",
      "size of square matrix:  512\n",
      "\n",
      "mul_sum(x, x):   14.8 us\n",
      "\n",
      "bmm(x, x):       37.4 us\n",
      "\n",
      "\n",
      "\n",
      "size of square matrix:  2048\n",
      "\n",
      "mul_sum(x, x):    8.4 us\n",
      "\n",
      "bmm(x, x):       33.8 us\n",
      "\n",
      "\n",
      "\n",
      "size of square matrix:  4096\n",
      "\n",
      "mul_sum(x, x):   10.3 us\n",
      "\n",
      "bmm(x, x):       24.6 us\n",
      "\n",
      "\n",
      "\n",
      "size of square matrix:  8192\n",
      "\n",
      "mul_sum(x, x):    7.4 us\n",
      "\n",
      "bmm(x, x):       34.2 us\n",
      "\n",
      "\n",
      "\n",
      "size of square matrix:  16384\n",
      "\n",
      "mul_sum(x, x):    7.0 us\n",
      "\n",
      "bmm(x, x):       23.4 us\n",
      "\n",
      "\n",
      "\n",
      "size of square matrix:  32768\n",
      "\n",
      "mul_sum(x, x):    6.4 us\n",
      "\n",
      "bmm(x, x):       23.4 us\n",
      "\n",
      "\n",
      "\n",
      "size of square matrix:  65536\n",
      "\n",
      "mul_sum(x, x):    7.0 us\n",
      "\n",
      "bmm(x, x):       23.1 us\n",
      "\n",
      "\n",
      "\n",
      "size of square matrix:  131072\n",
      "\n",
      "mul_sum(x, x):    6.8 us\n",
      "\n",
      "bmm(x, x):       23.2 us\n",
      "\n",
      "\n",
      "\n",
      "size of square matrix:  262144\n",
      "\n",
      "mul_sum(x, x):    6.7 us\n",
      "\n",
      "bmm(x, x):       24.7 us\n",
      "\n",
      "\n",
      "\n",
      "Benchmark execution:  2 \n",
      "\n",
      "\n",
      "\n",
      "size of square matrix:  512\n",
      "\n",
      "mul_sum(x, x):    6.9 us\n",
      "\n",
      "bmm(x, x):       23.5 us\n",
      "\n",
      "\n",
      "\n",
      "size of square matrix:  2048\n",
      "\n",
      "mul_sum(x, x):    6.4 us\n",
      "\n",
      "bmm(x, x):       23.8 us\n",
      "\n",
      "\n",
      "\n",
      "size of square matrix:  4096\n",
      "\n",
      "mul_sum(x, x):    6.8 us\n",
      "\n",
      "bmm(x, x):       23.0 us\n",
      "\n",
      "\n",
      "\n",
      "size of square matrix:  8192\n",
      "\n",
      "mul_sum(x, x):    6.8 us\n",
      "\n",
      "bmm(x, x):       22.7 us\n",
      "\n",
      "\n",
      "\n",
      "size of square matrix:  16384\n",
      "\n",
      "mul_sum(x, x):    6.7 us\n",
      "\n",
      "bmm(x, x):       23.0 us\n",
      "\n",
      "\n",
      "\n",
      "size of square matrix:  32768\n",
      "\n",
      "mul_sum(x, x):    6.5 us\n",
      "\n",
      "bmm(x, x):       27.2 us\n",
      "\n",
      "\n",
      "\n",
      "size of square matrix:  65536\n",
      "\n",
      "mul_sum(x, x):    7.0 us\n",
      "\n",
      "bmm(x, x):       23.6 us\n",
      "\n",
      "\n",
      "\n",
      "size of square matrix:  131072\n",
      "\n",
      "mul_sum(x, x):    6.4 us\n",
      "\n",
      "bmm(x, x):       23.8 us\n",
      "\n",
      "\n",
      "\n",
      "size of square matrix:  262144\n",
      "\n",
      "mul_sum(x, x):    6.6 us\n",
      "\n",
      "bmm(x, x):       23.1 us\n",
      "\n",
      "\n",
      "\n",
      "Benchmark execution:  3 \n",
      "\n",
      "\n",
      "\n",
      "size of square matrix:  512\n",
      "\n",
      "mul_sum(x, x):    6.8 us\n",
      "\n",
      "bmm(x, x):       22.7 us\n",
      "\n",
      "\n",
      "\n",
      "size of square matrix:  2048\n",
      "\n",
      "mul_sum(x, x):    6.4 us\n",
      "\n",
      "bmm(x, x):       23.2 us\n",
      "\n",
      "\n",
      "\n",
      "size of square matrix:  4096\n",
      "\n",
      "mul_sum(x, x):    6.7 us\n",
      "\n",
      "bmm(x, x):       23.2 us\n",
      "\n",
      "\n",
      "\n",
      "size of square matrix:  8192\n",
      "\n",
      "mul_sum(x, x):    6.6 us\n",
      "\n",
      "bmm(x, x):       23.4 us\n",
      "\n",
      "\n",
      "\n",
      "size of square matrix:  16384\n",
      "\n",
      "mul_sum(x, x):    6.7 us\n",
      "\n",
      "bmm(x, x):       23.3 us\n",
      "\n",
      "\n",
      "\n",
      "size of square matrix:  32768\n",
      "\n",
      "mul_sum(x, x):    6.5 us\n",
      "\n",
      "bmm(x, x):       23.6 us\n",
      "\n",
      "\n",
      "\n",
      "size of square matrix:  65536\n",
      "\n",
      "mul_sum(x, x):    6.8 us\n",
      "\n",
      "bmm(x, x):       22.7 us\n",
      "\n",
      "\n",
      "\n",
      "size of square matrix:  131072\n",
      "\n",
      "mul_sum(x, x):    6.7 us\n",
      "\n",
      "bmm(x, x):       23.0 us\n",
      "\n",
      "\n",
      "\n",
      "size of square matrix:  262144\n",
      "\n",
      "mul_sum(x, x):    6.7 us\n",
      "\n",
      "bmm(x, x):       23.0 us\n",
      "\n",
      "\n",
      "\n",
      "Benchmark execution:  4 \n",
      "\n",
      "\n",
      "\n",
      "size of square matrix:  512\n",
      "\n",
      "mul_sum(x, x):    6.5 us\n",
      "\n",
      "bmm(x, x):       23.3 us\n",
      "\n",
      "\n",
      "\n",
      "size of square matrix:  2048\n",
      "\n",
      "mul_sum(x, x):    6.4 us\n",
      "\n",
      "bmm(x, x):       23.3 us\n",
      "\n",
      "\n",
      "\n",
      "size of square matrix:  4096\n",
      "\n",
      "mul_sum(x, x):    6.8 us\n",
      "\n",
      "bmm(x, x):       25.2 us\n",
      "\n",
      "\n",
      "\n",
      "size of square matrix:  8192\n",
      "\n",
      "mul_sum(x, x):    7.0 us\n",
      "\n",
      "bmm(x, x):       24.3 us\n",
      "\n",
      "\n",
      "\n",
      "size of square matrix:  16384\n",
      "\n",
      "mul_sum(x, x):    7.0 us\n",
      "\n",
      "bmm(x, x):       23.5 us\n",
      "\n",
      "\n",
      "\n",
      "size of square matrix:  32768\n",
      "\n",
      "mul_sum(x, x):    6.7 us\n",
      "\n",
      "bmm(x, x):       23.1 us\n",
      "\n",
      "\n",
      "\n",
      "size of square matrix:  65536\n",
      "\n",
      "mul_sum(x, x):    6.5 us\n",
      "\n",
      "bmm(x, x):       27.1 us\n",
      "\n",
      "\n",
      "\n",
      "size of square matrix:  131072\n",
      "\n",
      "mul_sum(x, x):    6.9 us\n",
      "\n",
      "bmm(x, x):       23.6 us\n",
      "\n",
      "\n",
      "\n",
      "size of square matrix:  262144\n",
      "\n",
      "mul_sum(x, x):    6.6 us\n",
      "\n",
      "bmm(x, x):       23.3 us\n",
      "\n",
      "\n",
      "\n",
      "Benchmark execution:  5 \n",
      "\n",
      "\n",
      "\n",
      "size of square matrix:  512\n",
      "\n",
      "mul_sum(x, x):    6.9 us\n",
      "\n",
      "bmm(x, x):       23.2 us\n",
      "\n",
      "\n",
      "\n",
      "size of square matrix:  2048\n",
      "\n",
      "mul_sum(x, x):    6.5 us\n",
      "\n",
      "bmm(x, x):       23.2 us\n",
      "\n",
      "\n",
      "\n",
      "size of square matrix:  4096\n",
      "\n",
      "mul_sum(x, x):   10.2 us\n",
      "\n",
      "bmm(x, x):       24.6 us\n",
      "\n",
      "\n",
      "\n",
      "size of square matrix:  8192\n",
      "\n",
      "mul_sum(x, x):    6.7 us\n",
      "\n",
      "bmm(x, x):       23.1 us\n",
      "\n",
      "\n",
      "\n",
      "size of square matrix:  16384\n",
      "\n",
      "mul_sum(x, x):    6.5 us\n",
      "\n",
      "bmm(x, x):       25.5 us\n",
      "\n",
      "\n",
      "\n",
      "size of square matrix:  32768\n",
      "\n",
      "mul_sum(x, x):    6.9 us\n",
      "\n",
      "bmm(x, x):       23.8 us\n",
      "\n",
      "\n",
      "\n",
      "size of square matrix:  65536\n",
      "\n",
      "mul_sum(x, x):    7.1 us\n",
      "\n",
      "bmm(x, x):       24.1 us\n",
      "\n",
      "\n",
      "\n",
      "size of square matrix:  131072\n",
      "\n",
      "mul_sum(x, x):    6.6 us\n",
      "\n",
      "bmm(x, x):       23.5 us\n",
      "\n",
      "\n",
      "\n",
      "size of square matrix:  262144\n",
      "\n",
      "mul_sum(x, x):    6.6 us\n",
      "\n",
      "bmm(x, x):       23.1 us\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Printing the results\n",
    "with open('output_benchmark.out', 'r') as file:\n",
    "    for line in file.readlines():\n",
    "        print(line)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 96.222863,
   "end_time": "2021-04-15T15:50:15.715598",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-04-15T15:48:39.492735",
   "version": "2.3.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
